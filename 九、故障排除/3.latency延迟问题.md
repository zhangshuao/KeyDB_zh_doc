# 延迟问题疑难解答

本文档将帮助您了解如果KeyDB遇到延迟问题时可能出现的问题。

在此上下文中，延迟是客户端发出命令的时间和客户端接收到命令的回复时间之间的最大延迟。通常KeyDB的处理时间极低，在亚微秒范围内，但在某些条件下会导致更高的延迟数字。

## 我没时间了，把检查表给我

为了以低延迟的方式运行KeyDB，以下文档非常重要。不过，我知道我们都很忙，所以让我们从一个快速的清单开始。如果您未能遵循这些步骤，请返回此处阅读完整的文档。

    1、确保您没有运行正在阻塞服务器的缓慢命令。使用Redis慢日志功能来检查这个。
    2、对于EC2用户，确保使用基于HVM的现代EC2实例，比如m3.medium。否则fork()太慢了。
    3、必须在内核中禁用透明的巨大页面。使用echo never > /sys/kernel/mm/transparent_hugepage/enabled来禁用它们，并重新启动你的KeyDB进程。
    4、你正在使用一个虚拟机，有可能你有一个内在的延迟与KeyDB无关。使用./keydb-cli --intrinsic-latency 100检查运行时环境的最小延迟。注意:您需要在服务器中而不是在客户机中运行此命令。
    5、启用并使用KeyDB的延迟监视器特性，以获得对您的KeyDB实例中的延迟事件和原因的可读描述。

通常，使用下表来权衡持久性与延迟/性能之间的权衡，从更强的安全性到更好的延迟。

    1、AOF + fsync always: 这是非常慢的，你应该只有在你知道你在做什么的时候才使用它。
    2、AOF + fsync every second: 这是一个很好的折衷方案。
    3、AOF + fsync every second + no-appendfsync-on-rewrite option set to yes: 这和上面一样，但是在重写过程中避免了fsync，以降低磁盘压力。
    4、AOF + fsync never: 在这个设置中，Fsyncing取决于内核，甚至更少的磁盘压力和延迟峰值的风险。
    5、RDB: 根据您配置的save触发器，您可以进行大量的权衡。

现在，对于那些有15分钟时间的人来说，细节…

## 测量延迟

如果您遇到了延迟问题，您可能知道如何在应用程序的上下文中度量它，或者您的延迟问题非常明显，甚至在宏观上也是如此。
然而，keydb-cli可以用来衡量一个KeyDB服务器的延迟毫秒，只是尝试:

    keydb-cli --latency -h `host` -p `port`
     
## 使用内部KeyDB延迟监视子系统

自KeyDB 2.8.13以来，KeyDB提供了延迟监视功能，可以对不同的执行路径进行采样，以了解服务器阻塞的位置。
这使得本文档中所示问题的调试更加简单，因此我们建议尽快启用延迟监视。请参阅延迟监视器文档。

虽然延迟监视采样和报告功能将使了解KeyDB系统中的延迟源变得更简单，但仍建议您广泛阅读本文档，以更好地了解KeyDB和延迟峰值的主题。

## 延迟基线

有一种延迟是运行KeyDB的环境固有的一部分，即操作系统内核提供的延迟，如果您使用虚拟化，则由您使用的hypervisor提供的延迟。

虽然这个延迟无法消除，但研究它是很重要的，因为它是基线，或者换句话说，您将无法获得比在您的环境中运行的每个进程由于内核或hypervisor实现或设置而经历的延迟更好的KeyDB延迟。

我们称这种延迟为内在延迟，从keydb 2.8.7版开始的keydb-cli能够测量它。这是在入门级服务器上运行的Linux3.11.0下运行的示例。

注意：参数100是执行测试的秒数。我们运行测试的时间越长，就越有可能发现延迟峰值。100秒通常是合适的，但是您可能希望在不同的时间执行几次运行。
请注意，测试是CPU密集型的，可能会使系统中的单个内核饱和。

$ ./keydb-cli --intrinsic-latency 100
Max latency so far: 1 microseconds.
Max latency so far: 16 microseconds.
Max latency so far: 50 microseconds.
Max latency so far: 53 microseconds.
Max latency so far: 83 microseconds.
Max latency so far: 115 microseconds.

注意:在这种特殊情况下，keydb-cli需要在您运行或计划运行KeyDB的服务器上运行，而不是在客户机上。
在这种特殊模式下，keydb-cli根本不连接到KeyDB服务器: 它只是试图测量内核不提供CPU时间来运行到keydb-cli进程本身的最大时间。

在上面的例子中，系统的固有延迟只有0.115毫秒(或115微秒)，这是一个好消息，但是要记住，固有延迟可能随着时间的推移而改变，这取决于系统的负载。

虚拟环境不会显示这么好的数字，特别是在高负载或有噪声邻居的情况下。下面是在运行KeyDB和Apache的Linode 4096实例上的运行:

$ ./keydb-cli --intrinsic-latency 100
Max latency so far: 573 microseconds.
Max latency so far: 695 microseconds.
Max latency so far: 919 microseconds.
Max latency so far: 1606 microseconds.
Max latency so far: 3191 microseconds.
Max latency so far: 9243 microseconds.
Max latency so far: 9671 microseconds.

这里我们有一个9.7毫秒的固有延迟:这意味着我们不能要求更好的KeyDB。然而，在不同的虚拟化环境中，负载更高或邻居噪音更大的情况下，在不同时间运行的其他情况很容易显示出更糟糕的值。
我们能够在系统中测量到高达40毫秒的时间，否则系统显然是正常运行的.

## 由网络和通信引起的延迟

客户端使用TCP/IP连接或Unix域连接连接到KeyDB。1bit/s网络的典型延迟大约为200us，而使用Unix域套接字的延迟可以低至30us。
它实际上取决于您的网络和系统硬件。除了通信本身之外，系统还增加了一些延迟（由于线程调度、CPU缓存、NUMA放置等原因）。
在虚拟化环境中，系统诱导的延迟明显高于在物理机器上。

其结果是，即使KeyDB在亚微秒范围内处理大多数命令，执行多次服务器往返的客户机也必须为这些与网络和系统相关的延迟支付费用。

因此，一个高效的客户机将尝试通过将多个命令流水线连接在一起来限制往返次数。
服务器和大多数客户机都完全支持这一点。像MSET/MGET这样的聚合命令也可以用于此目的。
从KeyDB 2.4开始，许多命令还支持所有数据类型的可变参数。

以下是一些指导原则：

* 如果您能够负担得起，最好使用物理机器而不是VM来承载服务器。
* 不要系统地连接/断开到服务器(特别是基于web的应用程序)。让你的连接尽可能长久。
* 如果您的客户机与服务器位于同一主机上，请使用Unix域套接字。
* 更喜欢使用聚合命令(MSET/MGET)，或者在管道上使用可变参数的命令(如果可能的话)。
* 宁可使用流水线(如果可能的话)，也不要使用往返的顺序。
* KeyDB支持Lua服务器端脚本，以覆盖不适合原始管道操作的情况(例如，命令的结果是以下命令的输入)。


在Linux上，有些人可以通过处理进程放置（taskset）、cgroup、实时优先级（chrt）、NUMA配置（numactl）或使用低延迟内核来获得更好的延迟。
请注意，vanilla KeyDB并不真正适合绑定在单个CPU核心上。KeyDB可以派生非常耗费CPU的后台任务，比如bgsave或AOF rewrite。
这些任务决不能与主事件循环在同一个核心上运行。

在大多数情况下，不需要这些系统级优化。只有在你需要的时候，如果你熟悉的话，才去做。

## 由慢速命令生成的延迟

只运行一个线程的结果是，当一个请求服务速度慢时，所有其他客户端将等待此请求被服务。当执行普通命令时，比如GET或SET或LPUSH，这根本不是问题，因为这些命令是在恒定（非常小）的时间内执行的。但是，有许多命令在许多元素上操作，如SORT、LREM、SUNION和其他元素。例如，取两个大集合的交集可能需要相当长的时间。

建议运行多个服务器线程——服务器线程，以尝试提高性能。

如果您有延迟问题，则不应对由许多元素组成的值使用slow命令，或者应使用KeyDB replication运行副本，在其中运行所有慢速查询。考虑运行一个活动副本实例来利用您的资源。

可以使用KeyDB slow Log特性监视慢速命令。

此外，您可以使用您最喜欢的每个进程监视程序（top、htop、prstat等）快速检查主KeyDB进程的CPU消耗。如果它是高而流量不是，它通常是一个标志，慢命令使用。

**重要提示:** 在生产环境中使用KEYS命令是执行慢速命令时产生延迟的一个非常常见的原因。
正如KeyDB文档中记录的那样，keys应该只用于调试目的。由于KeyDB 2.8引入了一个新的命令，以迭代键空间和其他大型集合，请检查SCAN, SSCAN, HSCAN和ZSCAN命令以获得更多信息。
 
## fork产生的延迟

为了在后台生成RDB文件，或者在启用AOF持久性时重写仅追加文件，KeyDB必须派生后台进程。fork操作(在主线程中运行)本身就会导致延迟。

分叉在大多数类unix系统上是一项昂贵的操作，因为它涉及到复制大量链接到进程的对象。对于与虚拟内存机制关联的页表尤其如此。 

例如，在Linux/AMD64系统中，内存划分为4 kB的页面。为了将虚拟地址转换为物理地址，每个进程存储一个页表(实际上表示为树)，其中至少包含一个进程地址空间的每页指针。因此，一个大的24gb KeyDB实例需要一个24gb / 4kB * 8 = 48MB的页表。

当执行后台保存时，这个实例将不得不分叉，这将涉及分配和复制48mb的内存。它需要时间和CPU，特别是在虚拟机上，分配和初始化一个大的内存块可能非常昂贵。

## 不同系统中的fork时间

现代硬件在复制页表方面相当快，但Xen不行。Xen的问题不是特定于虚拟化，而是特定于Xen。例如，使用VMware或Virtual Box不会导致缓慢的fork时间。
下面是比较不同KeyDB实例大小的fork时间的表。执行BGSAVE并查看INFO命令输出中归档的latest_fork_usec获得数据。

然而，好消息是，基于EC2 HVM的新实例类型在使用fork时间方面要好得多，几乎与物理服务器相当，例如使用m3.medium (or better) 的实例将提供良好的结果。

* VMware上的Linux beefy VM 6.0GB RSS在77毫秒内forked(每GB 12.8毫秒)。
* 在物理机器上运行的Linux(未知的HW) 6.1GB RSS在80毫秒内forked(每GB 13.1毫秒)
* 运行在物理机器上的Linux (Xeon @ 2.27Ghz) 6.9GB RSS分成62毫秒(每GB 9毫秒)。
* 6sync (KVM)上的Linux虚拟机360mb RSS在8.2毫秒(每GB 23.3毫秒)内创建。
* 在EC2上的Linux VM，旧的实例类型(Xen) 6.1GB RSS在1460毫秒(每GB 239.3毫秒)内创建。
* 在EC2上的Linux VM，新的实例类型(Xen) 1GB RSS在10毫秒内forked(每GB 10毫秒)。
* Linode (Xen)上的Linux VM 0.9GBRSS forked 382毫秒(每GB 424毫秒)。

正如您可以看到的，某些运行在Xen上的vm的性能会受到一个到两个数量级的影响。对于EC2用户，建议很简单:使用现代的基于HVM的实例。 

## 由透明大页引起的延迟

不幸的是，当Linux内核启用了透明大页时，为了在磁盘上持久存储，在使用fork调用之后，KeyDB会导致巨大的延迟损失。大页是导致以下问题的原因:

1.调用Fork，创建两个具有共享大页面的进程。
2.在一个繁忙的实例中，运行几个事件循环将导致命令指向几千个页面，导致几乎整个进程内存的写时复制。
3.这将导致大的延迟和大的内存使用。

确保**禁用透明大页**使用以下命令:    

    echo never > /sys/kernel/mm/transparent_hugepage/enabled
 
## 由交换引起的延迟(操作系统分页)

Linux（和许多其他现代操作系统）能够将内存页从内存重新定位到磁盘，反之亦然，以便有效地使用系统内存。

如果KeyDB页被内核从内存移到交换文件中，当KeyDB使用存储在该内存页中的数据（例如访问存储在该内存页中的key）时，内核将停止KeyDB进程，以便将该页移回主内存。
这是一个缓慢的操作，涉及随机I/O（与访问已在内存中的页面相比），将导致KeyDB客户端出现异常延迟。

内核在磁盘上重新定位KeyDB内存页主要有三个原因：

1.由于正在运行的进程对物理内存的要求高于可用内存量，因此系统面临内存压力。这个问题最简单的例子就是KeyDB使用的内存比可用内存多。
2.KeyDB实例数据集（或数据集的一部分）大多完全空闲（客户端从未访问过），因此内核可以交换磁盘上的空闲内存页。
这个问题非常罕见，因为即使是一个速度稍慢的实例，也会经常碰到所有的内存页，迫使内核将所有的页保留在内存中。
3,一些进程正在系统上生成大量读或写I/O。因为文件通常是缓存的，所以它往往会对内核施加压力，以增加文件系统缓存，从而生成交换活动。
请注意，它包括KeyDB RDB和/或AOF后台线程，可以生成大文件。


幸运的是，Linux提供了很好的工具来调查这个问题，所以最简单的事情就是当怀疑由于交换而导致的延迟时，只需检查是否是这样。

首先要做的是检查在磁盘上交换的KeyDB内存量。为此，需要获取KeyDB实例pid：

    $ keydb-cli info | grep process_id
    process_id:5454

现在输入/proc文件系统目录的进程:

    $ cd /proc/5454

这里有一个名为smaps的文件，描述了KeyDB进程的内存布局(假设您使用的是Linux 2.6.16或更新版本)。
这个文件包含关于进程内存映射的非常详细的信息，一个名为Swap的字段正是我们要找的。
然而，由于smaps文件包含我们的KeyDB进程的不同内存映射(进程的内存布局比简单的线性页面数组更复杂)，所以并不只有一个交换字段。
 
因为我们对进程交换的所有内存感兴趣，所以要做的第一件事是在整个文件中交换字段的grep:

$ cat smaps | grep 'Swap:'
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                 12 kB
Swap:                156 kB
Swap:                  8 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  4 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  4 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  4 kB
Swap:                  4 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
Swap:                  0 kB
 

如果一切都是0kB，或者有零星的4k条目，那么一切都是完全正常的。实际上，在我们的示例实例中(一个运行KeyDB并每秒服务数百个用户的真实web站点)，有一些条目显示了更多的交换页面。
为了调查这是不是一个严重的问题，我们改变了我们的命令，以便也打印内存地图的大小:

$ cat smaps | egrep '^(Swap|Size)'
Size:                316 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  8 kB
Swap:                  0 kB
Size:                 40 kB
Swap:                  0 kB
Size:                132 kB
Swap:                  0 kB
Size:             720896 kB
Swap:                 12 kB
Size:               4096 kB
Swap:                156 kB
Size:               4096 kB
Swap:                  8 kB
Size:               4096 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:               1272 kB
Swap:                  0 kB
Size:                  8 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                 16 kB
Swap:                  0 kB
Size:                 84 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  8 kB
Swap:                  4 kB
Size:                  8 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  4 kB
Size:                144 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  4 kB
Size:                 12 kB
Swap:                  4 kB
Size:                108 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB
Size:                272 kB
Swap:                  0 kB
Size:                  4 kB
Swap:                  0 kB

从输出中可以看到，有一个720896kb的映射（只交换了12kb）和另外一个映射中交换了156kb的映射：基本上，我们的内存只有很少一部分被交换，所以这根本不会造成任何问题。

相反，若在磁盘上交换的进程内存量不小，则延迟问题可能和交换有关。如果KeyDB实例是这种情况，则可以使用vmstat命令进一步验证它：

$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0
 0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0
 0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0
 0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0
 2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0
 0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0
^C

我们需要的有趣的输出部分是两列si和so，这两列统计了从交换文件交换到交换文件的内存量如果在这两列中看到非零计数，则系统中存在交换活动。

最后，iostat命令可用于检查系统的全局I/O活动。

$ iostat -xk 1
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          13.55    0.04    2.92    0.53    0.00   82.95

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00
sdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85

如果延迟问题是由于KeyDB内存在磁盘上被交换，则需要降低系统中的内存压力，如果KeyDB使用的内存超过可用内存，则可以添加更多的RAM，或者避免在同一系统中运行其他内存不足的进程。

## AOF和磁盘I/O导致的延迟

另一个延迟源是由于KeyDB上只支持Append文件。AOF基本上使用两个系统调用来完成其工作。一个是write（2），用于将数据写入仅追加文件；另一个是fdatasync（2），用于刷新磁盘上的内核文件缓冲区，以确保用户指定的持久性级别。

write（2）和fdatasync（2）调用都可能是延迟的来源。例如，当正在进行系统范围的同步时，或者当输出缓冲区已满并且内核需要在磁盘上刷新以接受新的写入时，写（2）都可以阻止。

fdatasync（2）调用是一个更糟糕的延迟源，因为使用的内核和文件系统的许多组合可能需要几毫秒到几秒的时间才能完成，特别是在某些其他进程执行I/O的情况下。因此，在可能的情况下，KeyDB在KeyDB 2.4之后的其他线程中执行fdatasync（2）调用。

我们将看到配置如何影响使用AOF文件时的延迟量和延迟源。

可以使用appendfsync配置选项将AOF配置为以三种不同的方式在磁盘上执行fsync（可以在运行时使用CONFIG SET命令修改此设置）。

    * 当appendfsync设置为no KeyDB时，不执行fsync。在此配置中，唯一的延迟源可以是写（2）。当这种情况发生时，通常没有解决方案，因为简单地说，磁盘无法处理KeyDB接收数据的速度，但是，如果磁盘没有被执行I/O的其他进程严重减慢，这种情况是不常见的。
    * 当appendfsync设置为everysec KeyDB的值时，每秒执行一次fsync。它使用不同的线程，如果fsync仍在进行中，KeyDB使用一个缓冲区来延迟写入（2）调用最多2秒（因为如果fsync正在对同一文件进行写入，则在Linux上写将被阻止）。但是，如果fsync花费太长时间，KeyDB最终将执行write（2）调用，即使fsync仍在进行中，这可能是延迟的来源。
    * 当appendfsync设置为always时，在用OK代码回复客户机之前，每次写入操作都会执行fsync（实际上KeyDB会尝试将同时执行的许多命令集群到一个fsync中）。在这种模式下，性能通常很低，强烈建议使用能够在短时间内执行fsync的快速磁盘和文件系统实现。

大多数KeyDB用户将为appendfsync配置指令使用no或everysec设置。最小延迟的建议是避免其他进程在同一系统中执行I/O。
使用SSD磁盘也有帮助，但如果KeyDB在不执行任何查找的情况下向append-only文件中写入KeyDB时磁盘是空闲的，则即使是非SSD磁盘对append-only文件的性能也很好。

如果要调查与仅追加文件相关的延迟问题，可以在Linux下使用strace命令：
 
    sudo strace -p $(pidof keydb-server) -T -e trace=fdatasync
 
上面的命令将显示KeyDB在主线程中执行的所有fdatasync（2）系统调用。
使用上面的命令，当appendfsync config选项设置为everysec时，您将看不到后台线程执行的fdatasync系统调用。
为此，只需将-f开关添加到strace。

如果愿意，还可以使用以下命令查看fdatasync和write系统调用：

    sudo strace -p $(pidof keydb-server) -T -e trace=fdatasync,write

但是，由于write（2）也用于将数据写入客户端套接字，这可能会显示太多与磁盘I/O无关的内容。显然，无法告诉strace只显示慢速系统调用，因此我使用以下命令：

    sudo strace -f -p $(pidof keydb-server) -T -e trace=fdatasync,write 2>&1 | grep -v '0.0' | grep -v unfinished

## 过期生成的延迟

KeyDB以两种方式收回过期key：

* 一种惰性方法在命令请求key时使其过期，但发现该key已过期。
* 一个活动的方法每100毫秒会过期几个键。

假设ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP默认设置为20，并且该进程每秒执行10次，通常每秒只有200个密钥处于活动过期状态。
即使已经过期的key长时间不被访问，这也足以足够快地清理数据库，因此惰性算法没有帮助。同时，每秒仅过期200个key对KeyDB实例的延迟没有影响。

但是，该算法是自适应的，如果发现在采样key集中超过25%的key已经过期，则会循环。但假设我们每秒运行10次算法，这意味着随机样本中超过25%的密钥的不吉利事件至少在同一秒内过期。

基本上这意味着，如果数据库中有许多key在同一秒内过期，并且这些key至少占具有过期集的当前key总数的25%，那么KeyDB可以阻塞，以使已过期的key百分比低于25%。

为了避免对已经过期的key使用过多内存，这种方法是必需的，而且通常是绝对无害的，因为奇怪的是，大量key将在同一秒内过期，但用户在同一Unix时间内大量使用EXPIREAT并非不可能。

简而言之：请注意，许多同时过期的key可能是延迟的来源

## KeyDB软件看门狗

KeyDB 2.6引入了KeyDB软件看门狗，这是一个调试工具，用于跟踪那些由于某种原因而没有使用常规工具进行分析的延迟问题。

软件看门狗是一个实验性的特性。虽然它被设计用于生产环境，但在继续之前，应小心备份数据库，因为它可能与KeyDB服务器的正常执行有意外的交互。

重要的是，只有在无法通过其他方式追踪这一问题时，才将其作为最后手段。

这就是此功能的工作原理：

* 用户使用CONFIG SET命令启用软件监视器。
* KeyDB开始不断地监视自己。
* 如果KeyDB检测到服务器被阻止执行某些返回速度不够快的操作，并且这可能是延迟问题的根源，则会在日志文件中转储有关服务器被阻止位置的低级报告。
* 用户联系开发人员，在KeyDB Google组中编写消息，包括消息中的监视程序报告。

请注意，不能使用KeyDB.conf文件启用此功能，因为它设计为仅在已运行的实例中启用，并且仅用于调试目的。

要启用此功能，请使用以下命令：

    CONFIG SET watchdog-period 500

以毫秒为单位指定周期。在上面的示例中，我指定只在服务器检测到500毫秒或更大的延迟时记录延迟问题。最小可配置周期为200毫秒。

使用完软件看门狗后，可以将其关闭，并将看门狗周期参数设置为0。重要提示：记住要这样做，因为将实例的看门狗打开的时间比需要的时间长通常不是一个好主意。

下面是一个示例，说明当软件监视程序检测到比配置的延迟更长的延迟时，您将在日志文件中看到打印的内容：

    [8547 | signal handler] (1333114359)
    --- WATCHDOG TIMER EXPIRED ---
    /lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]
    /lib/libpthread.so.0(+0xf8f0) [0x7f16b5f158f0]
    /lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]
    /lib/libc.so.6(usleep+0x34) [0x7f16b5c62844]
    ./keydb-server(debugCommand+0x3e1) [0x43ab41]
    ./keydb-server(call+0x5d) [0x415a9d]
    ./keydb-server(processCommand+0x375) [0x415fc5]
    ./keydb-server(processInputBuffer+0x4f) [0x4203cf]
    ./keydb-server(readQueryFromClient+0xa0) [0x4204e0]
    ./keydb-server(aeProcessEvents+0x128) [0x411b48]
    ./keydb-server(aeMain+0x2b) [0x411dbb]
    ./keydb-server(main+0x2b6) [0x418556]
    /lib/libc.so.6(__libc_start_main+0xfd) [0x7f16b5ba1c4d]
    ./keydb-server() [0x411099]
    ------

注意：在示例中，使用了**DEBUG SLEEP**命令来阻止服务器。如果服务器在不同的上下文中阻塞，则堆栈跟踪是不同的。

