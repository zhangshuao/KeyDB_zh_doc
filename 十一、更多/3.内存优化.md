# 内存优化

这一页正在进行中。目前它只是一个清单，如果你有记忆问题，你应该检查一下内存。

## 小聚合数据类型的特殊编码

由于KeyDB 2.2许多数据类型都经过了优化，以使用小于等于某个大小的空间。散列、列表、由整数组成的集合和排序的集合，当小于给定数量的元素，并且达到最大元素大小时，以非常高效的存储器方式进行编码，使用最多10倍的内存（使用5倍的内存作为平均保存）。
从 用户 和 API的角度来看，这是完全透明的。由于这是CPU/内存折衷，因此可以使用以下KeyDB.CONF指令调整特殊编码类型的元素的最大数量和最大元素大小。

    hash-max-zipmap-entries 512 (hash-max-ziplist-entries for KeyDB >= 2.6)
    hash-max-zipmap-value 64  (hash-max-ziplist-value for KeyDB >= 2.6)
    list-max-ziplist-entries 512
    list-max-ziplist-value 64
    zset-max-ziplist-entries 128
    zset-max-ziplist-value 64
    set-max-intset-entries 512

如果特殊编码的值将溢出配置的最大大小，KeyDB将自动将其转换为正常编码。对于较小的值，此操作非常快，但是如果更改设置以便对更大的聚合类型使用特殊编码的值，建议运行一些基准测试以检查转换时间。

## 使用32 bit的实例

使用32位目标编译的KEYDB使用每个key的内存更少，因为指针很小，但是这样的实例将被限制到4GB的最大内存使用。要将KeyDB编译为32位二进制文件，请使用make 32bit。
RDB和AOF文件在32位和64位实例之间（当然也在小端和大端之间）是兼容的，因此您可以从32位切换到64位，或者相反，没有问题。

## 位和字节级操作

KeyDB 2.2引入了新的位和字节级操作：GETRANGE、SETRANGE、GETBIT和SETBIT。
使用这些命令，可以将KeyDB字符串类型视为随机访问数组。例如，如果您有一个应用程序，其中用户由一个唯一的累进整数标识，则可以使用位图保存有关用户性别的信息，为女性设置位，为男性清除位，或者采用其他方式。
对于1亿用户来说，在KeyDB实例中，这些数据只需要12兆的RAM。您可以使用GETRANGE和SETRANGE执行相同的操作，以便为每个用户存储一个字节的信息。
这只是一个例子，但实际上可以用这些新的原语在很小的空间内模拟许多问题。

## 尽可能使用散列(hashes)

小散列是在一个非常小的空间中编码的，所以每次可能的时候都应该尝试使用散列来表示数据。
例如，如果在web应用程序中有表示用户的对象，而不是对名称、姓氏、电子邮件、密码使用不同的键，则使用一个包含所有必需字段的散列。

如果你想了解更多，请阅读下一节。

## 使用散列抽象KeyDB上非常节省内存的普通键值存储

基本上，可以使用KeyDB对纯键值存储进行建模，其中的值可以只是字符串，这不仅比KeyDB纯键值更节省内存，而且比memcached节省内存。

让我们从一个事实开始：几个键比包含一些字段的散列的单个键使用更多的内存。这怎么可能？我们用一个诡计。理论上，为了保证我们在恒定时间内执行查找（也被称为O（1）中的大O表示法），需要在平均情况下使用具有恒定时间复杂度的数据结构，例如哈希表。

但很多时候散列只包含几个字段。当散列很小时，我们可以将其编码为O（N）数据结构，就像一个带长度前缀的键值对的线性数组。因为我们只在N很小的时候才这样做，所以HGET和HSET命令的摊销时间仍然是O（1）：一旦散列包含的元素太多，散列将被转换成一个真正的散列表（您可以在KeyDB.conf中配置限制）。

从时间复杂度的角度来看，这并不是很好，但也从固定时间的角度来看，因为键值对的线性阵列恰好与CPU缓存（它具有比哈希表更好的缓存局部性）很好地发挥作用。

但是，由于散列字段和值（始终）不表示为功能齐全的KeyDB对象，因此散列字段不能像真正的键那样有关联的生存时间（过期），并且只能包含字符串。但是我们可以这样做，这是设计hash数据类型API时的意图（我们信任简单性而不是特性，因此不允许嵌套数据结构，因为不允许单个字段过期）。

所以散列是内存高效的。当使用散列表示对象或在存在相关字段组时建模其他问题时，这非常有用。但如果我们有一个简单的关键价值业务呢？

假设我们想使用KeyDB作为许多小对象的缓存，这些小对象可以是JSON编码的对象、小HTML片段、简单键->布尔值等等。基本上，任何东西都是一个带有小键和值的字符串->字符串映射。

现在假设要缓存的对象是编号的，例如：

    * object:102393
    * object:1234
    * object:5

这就是我们能做的。每次需要执行SET操作来设置新值时，我们实际上会将密钥分成两部分，一部分用作key，另一部分用作哈希的字段名。例如，名为"object:1234"的对象实际上被拆分为：

    * 一个名为object的键：12
    * 名为34的字段

因此，我们使用所有字符，但最新的两个字符用于键，最后两个字符用于哈希字段名。要设置key，请使用以下命令：

    HSET object:12 34 somevalue

如您所见，每个散列将结束包含100个字段，这是CPU和存储内存之间的最佳折衷。

还有一件非常重要的事情要注意，使用这个模式，每个哈希都将有或多或少的100个字段，而不管我们缓存了多少对象。
这是因为我们的对象总是以数字结尾，而不是随机字符串。在某种程度上，最终的数字可以看作是一种隐式预切分的形式。

## 内存分配

为了存储用户key，KeyDB最多分配maxmemory设置启用的内存（但是可能会有少量的额外分配）。

确切的值可以在配置文件中设置，也可以稍后通过配置集设置（有关更多信息，请参阅使用内存作为LRU缓存）。关于KeyDB如何管理内存，需要注意以下几点：

    当删除key时，KeyDB不会总是释放（返回）内存到操作系统。这不是KeyDB的特殊之处，但它是大多数 malloc() 实现的工作方式。例如，如果用5GB的数据填充一个实例，然后删除相当于2GB的数据，则常驻集大小（也称为RSS，即进程消耗的内存页数）可能仍为5GB左右，即使KeyDB将声明用户内存为3GB左右。发生这种情况的原因是底层分配器无法轻松释放内存。
    例如，通常大部分移除的key被分配在与仍然存在的其他key相同的页面中。

    前一点意味着您需要根据您的峰值内存使用量来配置内存。如果您的工作负载不时需要10GB，即使大多数情况下5GB可以做到，您也需要为10GB做准备。

    但是分配器是智能的，并且能够重用空闲的内存块，因此在释放了2GB的5GB数据集之后，当您再次开始添加更多的key时，您将看到RSS(常驻集大小)保持稳定，不会增加更多，因为您添加了2GB的额外key。
    分配器基本上是试图重用先前(逻辑上)释放的2GB内存。

    由于这些原因，当内存使用率在峰值时远大于当前使用的内存时，碎片率是不可靠的。
    碎片计算为当前使用的内存量（KeyDB执行的所有分配的总和）除以实际使用的物理内存（RSS值）。
    因为RSS反映了峰值内存，当（实际上）使用的内存很低，因为释放了很多键/值，但是RSS很高时，mem_used/RSS的比率将非常高。

如果没有设置maxmemory，KeyDB会在找到合适的内存时继续分配内存，因此它会(逐渐)耗尽所有可用内存。
因此，通常建议配置一些限制。您可能还希望将maxmemory-policy设置为noeviction（这不是某些旧版本KeyDB中的默认值）。

它使KeyDB在达到极限时返回写命令的内存不足错误，这反过来可能导致应用程序出错，但不会因为内存不足而使整个机器死机。



