# 使用 Sentinel 哨兵

KeyDB有在Redis中派生的Sentinel的使用选项，但是在提供活动复制选项的情况下，Sentinel不是必需的，使用起来可能更复杂。
但是，如果您正在通过Redis项目进行迁移，那么KeyDB仍将使用Sentinel实例设置。

## KeyDB Sentinel 文档

KeyDB Sentinel为KeyDB提供高可用性。实际上，这意味着使用Sentinel，您可以创建一个KeyDB部署，
它可以在没有人为干预的情况下抵抗某些类型的失败。

KeyDB Sentinel还提供其他辅助任务，如监视、通知，并充当客户端的配置提供程序。

这是宏观层面（即大图片）哨兵能力的完整列表:

**监测** 哨兵经常检查您的主实例和从实例是否按预期工作。

**通知** Sentinel可以通过API通知系统管理员，另一个计算机程序，其中一个被监视的KeyDB实例有问题。

**自动故障转移** 如果主服务器没有按预期工作，Sentinel可以启动一个故障转移过程，其中一个从服务器被提升为主服务器，
               其他的从服务器被重新配置为使用新的主服务器，并且使用KeyDB服务器的应用程序在连接时通知要使用的新地址。

**配置提供程序** Sentinel充当客户端服务发现的授权源：客户端连接到Sentinel以请求负责给定服务的当前KeyDB主机的地址。
               如果发生故障转移，Sentinels将报告新地址。

## Sentinel 分布性

KeyDB Sentinel是一个分布式系统：

Sentinel本身被设计成在一个配置中运行，其中有多个Sentinel进程协同工作。多个哨兵进程协作的优点如下：

1.当多个哨兵同意给定的主服务器不再可用时，执行故障检测。这降低了误报的可能性。
2.即使不是所有的Sentinel进程都在工作，Sentinel也能工作，从而使系统能够抵抗故障。
  毕竟，拥有一个本身就是单一故障点的故障切换系统是没有乐趣的。

Sentinel、KeyDB实例（主服务器和从服务器）以及连接Sentinel和KeyDB的客户端的总和也是一个具有特定属性的大型分布式系统。
在本文档中，概念将逐步引入，从理解Sentinel的基本属性所需的基本信息，到更复杂的信息（可选信息），
以了解Sentinel是如何工作的。

# KeyDB Sentinel 规范

## 介绍

KeyDB Sentinel是当前正在开发的KeyDB高可用性解决方案的名称。它与KeyDB Cluster无关，是供不需要KeyDB Cluster的人使用的，
只是在主实例不能正常工作时执行自动故障转移的一种方法。

计划是在短时间内，最好在2012年7月中旬，提供一个可用的KeyDB Sentinel测试版实现。

简而言之，KeyDB Sentinel将能够做到：

* 监视主实例和从实例以查看它们是否可用。
* 当主从失败时，提升主从。
* 选择从机时修改客户端配置。
* 使用通知将事件通知系统管理员。

因此，KeyDB Sentinel的三种不同角色可以概括为以下三大方面：

    监测。
    通知。
    自动故障转移。

以下文档说明了为实现此目标而设计的KeyDB Sentinel。

# KeyDB Sentinel 思想

KeyDB Sentinel的思想是在网络的不同位置有多个"监视设备"，监视KeyDB主实例。
然而，这些独立的设备不能在没有其他哨兵同意的情况下运行。
一旦检测到KeyDB主实例失败，为了启动故障转移过程，sentinel必须验证是否存在给定级别的协议。
哨兵的数量、它们在网络中的位置以及配置的仲裁，在许多可能性中选择所需的行为。
KeyDB Sentinel不使用任何代理：客户端重新配置是以用户设置特定的方式运行用户提供的可执行文件（例如shell脚本或Python程序）来执行的。

## 以什么形式装运

KeyDB Sentinel只是KeyDB服务器可执行文件的一种特殊模式。

如果使用"keydb-sentinel"作为argv[0]调用keydb服务器（例如使用符号链接或复制文件），或者如果传递--sentinel选项，
keydb实例将以sentinel模式启动，并且只理解与sentinel相关的命令。所有其他命令都将被拒绝。

sentinel的整个实现将生活在一个分离的文件sentinel.c中，对其余代码库的影响最小。但是，此解决方案允许使用KeyDB中已实现的所有工具，
而无需重新实现它们或维护KeyDB Sentinel的独立代码库。

## Sentinels 网络

所有的哨兵都有持续的联系：

* 被监视的主人。
* 所有的从机，都是通过主机的信息输出发现的。
* 所有其他的哨兵连接到这个主人，通过Pub/Sub发现。

哨兵使用KeyDB协议相互交谈，并回复外部client。

KeyDB Sentinels导出SENTINEL命令。SENTINEL命令的子命令用于执行不同的操作。

例如，SENTINEL masters命令枚举所有被监视的主服务器及其状态。
不过，Sentinel也可以作为普通KeyDB实例来回复PING命令，因此可以将Sentinel视为普通KeyDB实例来监视它。

每个哨兵执行的网络任务列表如下：

* 哨兵 每5秒使用主 发布/订阅 多次发布其状态。
* 哨兵 使用TCP端口接受命令。默认情况下，端口为26379。
* 哨兵 经常监视master、slave和其他发送PING命令的哨兵。
* 哨兵 每10秒向主从发送一次信息命令，以便获取连接的从机的新列表、主机的状态等。
* 哨兵 监视哨兵 Pub/Sub "hello" 管道，以便发现新连接的哨兵，或检测不再连接的哨兵。管道使用 __sentinel__:hello。

## Sentinels 发现

为了使哨兵的配置尽可能简单，每个哨兵使用KeyDB master Pub/Sub功能广播其存在。

每个哨兵都订阅同一个频道，并将其存在的信息广播到同一个频道，包括哨兵的运行ID，以及侦听命令的IP地址和端口。

每个哨兵都维护一个其他哨兵运行ID、IP和端口的列表。如果某个哨兵使用Pub/Sub的时间过长，而该哨兵不再宣布其存在，则该哨兵将从列表中删除，
前提是master哨兵似乎工作正常。在这种情况下，会向系统管理员发送通知。

# 检测失败的master

从KeyDB Sentinel的角度来看，一个实例在连续超过指定秒数的时间内无法正确响应PING命令时，该实例不可用。

要使PING答复被视为有效，应满足以下条件之一：

* PING以 +PONG 回复。
* PING以 -LOADING 错误回复。
* PING以 +MASTERDOWN 错误回复。

不可接受的答复：

* PING以 -BUSY 错误回复。
* PING以 -MISCONF 错误回复。
* 超过指定毫秒数后未收到PING回复.

PING不应使用与上面列出的错误代码不同的错误代码进行回复，但KeyDB Sentinel认为任何其他错误代码都是可接受的回复。

# -BUSY 状态 处理

当脚本运行的时间超过配置的脚本时间限制时，将返回 -BUSY错误。在触发故障转移之前发生这种情况时，
KeyDB Sentinel将尝试发送一个 "SCRIPT KILL" 命令，只有在脚本为read-only时才会成功。

# 主客观下

从哨兵的角度来看，主设备有两种不同的错误条件：

* 主观上向下（又称 S_DOWN）意味着从哨兵的角度来看主人是向下的。
* 客观上向下（也称 O_DOWN）意味着从足够的哨兵的角度来看，主站主观上向下，以达到该主站的配置法定人数。

## Sentinel 如何同意标记一个 O_DOWN master

一旦哨兵检测到一个主站处于关机状态，它就会开始发送其他哨兵，哨兵每秒通过addr请求一次主站关机。回复存储在每个哨兵记忆中的状态中。

每秒10次，哨兵扫描状态，并检查是否有足够的哨兵认为主服务器已关闭（这不是此操作的具体情况，大多数状态检查都是使用此频率执行的）。

如果此哨兵已经有此主控的S_DOWN条件，并且有足够的其他哨兵最近报告了此条件（有效时间当前设置为5秒），则主控标记为O_DOWN（客观上向下）。

注意，O_DOWN状态不会在哨兵之间传播。每个哨兵都能独立到达这个状态。

# Sentinel is-master-down-by-addr 命令

哨兵使用SENTINEL is-master-down-by-addr 命令，从本地角度向其他哨兵询问主人的状态。
此命令使用布尔值（以0或1整数答复的形式，作为多个批量回复的第一个元素）进行回复。

但是，为了避免误报，该命令按以下方式操作：

* 如果指定的ip和端口未知，则返回0。
* 如果找到指定的ip和端口但不属于主实例，则返回0。
* 如果哨兵处于倾斜模式（参见本文档后面部分），则返回0。
* 只有在已知实例为master、标记为S_DOWN且哨兵处于倾斜模式时，才返回值1。

## 删除重复 Sentinels

为了达到配置的仲裁，我们绝对希望确保不同的物理Sentinel实例达到仲裁。在任何情况下，我们都不应该从同一个实例获得一致意见，
因为某些原因，该实例似乎是两个或多个不同的哨兵实例。

这是通过主动删除重复的Sentinel来实现的：每当Sentinel在Hello Pub/Sub频道中发送带有其地址和runid的消息时，
如果在Sentinels表中找不到与该master完全匹配的（相同的runid和地址），我们将删除具有相同runid或相同地址的任何其他Sentinel。
然后添加新的哨兵。

例如，如果重新启动Sentinel实例，则运行ID将不同，具有相同IP地址和端口对的旧Sentinel将被删除。

## 启动故障转移：领导者和观察者

主节点标记为O_DOWN的事实不足以启动故障转移过程。什么哨兵应该启动故障转移也有待决定。

sentinel也可以通过两种方式配置：只能作为无法执行故障转移的监视器，或者作为可以启动故障转移的sentinel。

需要的是，只有一个Sentinel才会启动故障转移过程，应该在允许执行故障转移的Sentinel中选择这个Sentinel。

在Sentinel中，故障转移期间有两个角色：

Leader Sentinel是选择用来执行故障转移的。
观察者Sentinel是其他Sentinel，只是在故障转移过程之后不执行活动操作。

因此，启动故障转移的条件是：

一个 Master O_DOWN 条件.
一个 被选为领袖 的 哨兵.

## Sentinel Leader选举

选举过程如下：

* 每一个主控处于关闭状态的哨兵用10 HZ的频率更新其内部状态，以从其角度刷新什么是主观领导者。

每个哨兵都会用这种方式选出一个主观的领导者。

* 我们所知道的关于给定主服务器的每一个Sentinel都是可能的候选者，它是可访问的（没有关闭状态），允许执行故障转移（这个Sentinel特定的配置是使用Hello通道传播的）。
* 在所有可能的候选者中，选择具有字典式较小的Run ID的候选人。

每次哨兵用addr命令回复主人是哨兵，它也用主观性领队的Run ID回复。

每一个主控失败的哨兵（OúDOWN）以10 HZ 的频率检查其主观领队和所有其他哨兵的主观领队，
如果出现以下情况，将自己标记为leader：

* 它是自己的主观领导者。
* 至少有N-1个其他哨兵看到主人倒下，并且可以到达，也认为是首领。N是为此主机配置的仲裁。
* 至少50%+1参与投票过程的哨兵（可以到达，也可以看到主人失败）应该同意leader。

因此，例如，如果总共有三个哨兵，主哨兵失败了，三个哨兵都能通信（没有哨兵失败），并且此主哨兵的配置法定人数是2，
那么哨兵会觉得自己是一个客观的领导者，如果至少它和另一个哨兵同意它是主观的领导者。

一旦Sentinel检测到它是目标leader，它就会用FAILOVER_IN_PROGRESS和IM_the_leader标记标记主节点，
并以Sentinel_FAILOVER_DELAY（当前5秒）加上0毫秒到10000毫秒之间的随机附加时间启动故障转移进程。

在这段时间里，我们以每秒一次（通常是10秒）的频率向所有的slave询问信息。如果一个从机同时变成一个主机，
则故障转移被挂起，并且引导器清除IM_the_Leader标志，将自己变成一个观察者。

## Leader选举过程的保障

正如你所看到的，哨兵要想成为leader，并不严格要求多数。用户只需将主仲裁设置为5（例如，如果总共有9个哨兵），就可以强制需要多数。

但是，也可以将quorum设置为2和9个sentinel的值，以提高对netsplits、失败sentinel或其他错误条件的抵抗力。
在这种情况下，针对竞争条件（多个哨兵同时开始执行故障转移）的保护是通过用于启动故障转移的随机延迟和slave实例的连续监视来提供的，
以检测是否另一个哨兵（或一个人）启动了故障转移过程。

此外，使用一个确定的过程来选择要提升的slave，以最小化两个具有工作奴隶全部视野的不同哨兵选择两个不同奴隶进行提升的机会。

然而，可以很容易地想象netsplits和特定的配置，其中两个哨兵可能开始同时充当领导者，在无法通信的网络的两个不同部分选择两个不同的奴隶作为主服务器。
KeyDB Sentinel用户应评估网络拓扑，并根据自己的目标和不同的权衡选择适当的仲裁。

## 观察者如何理解故障转移已启动

观察家只是一个哨兵，他不相信自己是leader，但仍然看到一个主人处于困境。

观察者仍然能够根据故障转移发生的情况跟踪和更新内部状态，但不直接依赖于负责人与之通信以了解进展情况。
它只是观察slave的状态来了解正在发生的事情。

特别是，如果连接到master设备的slave设备变为主设备（观察员可以在信息输出中看到），观察员会将主设备标记为正在进行故障转移。
当所有其他可访问的从机看起来都是此slave的slave（已转换为主机）时，观察者还将认为故障转移已完成。

如果一个从机正在进行故障转移，并且故障转移没有进行太长时间，同时其他哨兵开始声称这个哨兵是目标领导者（例如，因为旧的领导者已经不可访问），
哨兵会将自己标记为IM领导者，并继续进行故障转移。

注：所有的哨兵状态，包括主客观领导，都是一个动态的过程，持续刷新周期为10 Hz。哨兵没有"一次性决定"的步骤。

## 选择Slave提升

如果master服务器有多个slave服务器，则选择要升级到master服务器的slave服务器，检查slave服务器优先级（通过信息输出传播的KeyDB实例的新配置选项），
并选择优先级值较低的一个（它是一个类似于DNS系统MX字段的整数）。所有长时间与主服务器断开连接的slave服务器都将被丢弃（陈旧数据）。

如果存在相同优先级的奴隶，则选择具有字典上较小的Run ID的一个。

如果由于所有slave都失败而没有要选择的slave，则根本不会启动故障转移。
相反，如果没有要选择的slave服务器，因为master服务器从未在监视会话中使用过slave服务器，则尽管如此，故障转移仍将执行，只是调用用户脚本。
但是，要发生这种情况，必须为该 master服务器设置一个特殊的配置选项（在没有slave服务器的情况下强制故障转移）。

这很有用，因为有些配置中，脚本可以在IP协议级别配置新实例，但没有附加的slave。

## 故障转移过程

故障转移过程包括以下步骤：

* 使用SLAVEOF NO ONE命令将选定的slave变成主机。
* 把剩下的slave，如果有的话，都交给新主人的slave。这是以增量方式完成的，一个slave接着一个slave，
  等待上一个slave完成同步过程，然后再开始下一个slave。
* 调用用户脚本以通知客户端配置已更改。
* 从表中完全删除旧的失败主控形状，并添加同名的新主控形状。

如果步骤"1"失败，则故障转移将中止。
所有其他错误都被认为是非致命的。

## 倾斜TILT 模式

KeyDB Sentinel在很大程度上依赖于计算机时间：例如，为了了解实例是否可用，它会记住对PING命令最新成功应答的时间，
并将其与当前时间进行比较，以了解它的使用时间。

但是，如果计算机时间以意外的方式改变，或者如果计算机很忙，或者进程由于某种原因被阻塞，Sentinel可能会以意外的方式开始工作。

倾斜模式是一种特殊的"保护"模式，当检测到可能降低系统可靠性的异常情况时，哨兵可以进入该模式。
Sentinel计时器中断通常每秒调用10次，因此我们预计对计时器中断的两次调用之间的间隔大约为100毫秒。

哨兵所做的是注册前一次定时器中断，并将其与当前呼叫进行比较：如果时差为负或出乎意料地大（2秒或更多），
则进入倾斜模式（或者如果它已经进入倾斜模式退出的延迟）。

当处于倾斜模式时，哨兵将继续监视一切，但是：

* 它完全停止了活动。
* 它开始消极地回复SENTINEL is-master-down-by-addr请求，因为不再信任检测故障的能力。

如果在30秒钟内一切正常，则退出倾斜模式。

## Sentinel 监视 其他 sentinel

当哨兵不再使用Pub/Sub频道进行太长时间的广告（比master服务器的配置超时多30分钟），
但同时master服务器似乎正常工作时，哨兵将从该master服务器的哨兵表中删除，并向系统管理员发送通知。

## 用户提供的脚本

哨兵可以选择调用用户提供的脚本来执行两项任务：

* 通知客户端配置已更改。
* 将问题通知系统管理员。

用于通知客户端配置更改的脚本具有以下参数：

* ip:port 调用哨兵的端口
* 旧主 ip:port
* 新主 ip:port

使用以下参数调用发送通知的脚本：

p:port 调用哨兵的端口。
要传递给系统管理员的消息将写入标准输入。

使用调用sentinel的ip:port，如果需要，脚本可以调用sentinel子命令来获取更多信息。

通知脚本的具体实现可能使用"mail"命令或其他一些命令来传递SMS消息、电子邮件、tweets。

在web应用程序中修改配置的脚本实现可能会使用HTTP GET请求来强制客户端更新配置，或者使用特定设置的任何其他合理机制。

## 设置示例

假想设置：

    computer A runs the KeyDB master.
    computer B runs the KeyDB slave and the client software.

在这种简单的配置中，可以放置一个sentinel，将"minimal agreement"设置为1的值（不需要其他sentinel的确认），
运行在"B"上。

如果"A"失败，故障转移过程将启动，从机将被选为主机，客户端软件将被重新配置。
假想设置：

    computer A runs the KeyDB master
    computer B runs the KeyDB slave
    computer C,D,E,F,G are web servers acting as clients

在这个设置中，可以在C、D、E、F、G处运行5个哨兵，"最小协议"设置为3。

在实际的生产环境中，需要评估不同的计算机是如何连接在一起的，并检查在网络拆分期间发生了什么，
以便选择将哨兵放置在何处，以及最小协议的级别，以便网络故障的单臂不会触发故障转移。

一般而言，如果存在复杂的网络拓扑，则最小协议应设置为同一网络臂中同时存在的最大哨兵数，加上一个。

## Sentinel 子命令

SENTINEL masters, 提供已配置的master形状的列表。
SENTINEL slaves <master name>, 提供具有指定名称的主机的slave列表。
SENTINEL sentinels <master name>, 提供具有指定名称的主机的sentinels列表。
SENTINEL is-master-down-by-addr <ip> <port>, 返回两个元素的多批量回复，其中第一个元素是：0或：1，第二个元素是故障转移的主观先导

# TODO

更详细的用户脚本错误处理规范，包括返回代码的含义，如0：重试。1:致命错误。2:再试一次，以此类推。
更详细地说明当用户脚本在给定时间内不返回时会发生什么。
为配置更改添加"推送"通知系统。
对于每个被监视的主控形状，配置为所有SENTINEL命令报告的主控形状指定一个名称。
明确我们处理一个单一的哨兵监控多个master。

# 快速启动

## 获得 Sentinel

当前版本的Sentinel称为Sentinel 2。它是对最初的Sentinel实现的重写，使用更强大和更简单的预测算法（在本文档中进行了解释）。

KeyDB Sentinel的稳定版本是从KeyDB 2.8开始发布的。

在不稳定的分支中执行新的开发，并且新的特性有时在被认为是稳定的时被重新移植到最新的稳定分支中。

KeyDB 2.6附带的KeyDB Sentinel版本1已弃用，不应使用。

## 运行 Sentinel

如果您使用的是keydb-sentinel可执行文件（或者如果您有一个与keydb服务器可执行文件同名的符号链接），
则可以使用以下命令行运行sentinel：

    keydb-sentinel /path/to/sentinel.conf

否则，您可以直接使用keydb-server可执行文件在Sentinel模式下启动它

    keydb-server /path/to/sentinel.conf --sentinel
 
两种方法都是一样的。
 
但是，在运行Sentinel时必须使用配置文件，因为系统将使用此文件来保存在重新启动时重新加载的当前状态。
如果没有配置文件或者配置文件路径不可写，Sentinel将拒绝启动。

默认情况下，Sentinel运行侦听到TCP端口26379的连接，因此要使Sentinel工作，必须打开服务器的端口26379才能从其他Sentinel实例的IP地址接收连接。
否则，哨兵无法交谈，也无法就如何操作达成一致，因此永远不会执行故障转移。 
    
## 部署前了解Sentinel的基本知识

您至少需要三个Sentinel实例才能进行健壮的部署。

这三个Sentinel实例应该放置在计算机或虚拟机中，这些计算机或虚拟机被认为是以独立方式失败的。例如，不同的物理服务器或虚拟机在不同的可用性区域上执行。

Sentinel+KeyDB分布式系统不保证在故障期间保留已确认的写入，因为KeyDB使用异步复制。然而，有一些部署Sentinel的方法会使窗口丢失写操作的时间限制在某些特定的时刻，而还有其他一些不太安全的方法来部署它。

你的客户需要哨兵的支持。流行的客户端库有Sentinel支持，但不是全部。

如果您不在开发环境中不时地进行测试，或者如果您可以在生产环境中进行测试（如果它们可以工作的话），则没有安全的HA设置。你可能有一个错误的配置，只有在太迟的时候（凌晨3点，你的主人停止工作）才会变得明显。

**Sentinel、Docker或其他形式的网络地址转换或端口映射应小心混合：** Docker执行端口重新映射，中断Sentinel自动发现其他Sentinel进程和主进程的从属列表。
请查看本文档后面关于Sentinel和Docker的部分以了解更多信息。

## 配置 Sentinel

KeyDB源分发包含一个名为sentinel.conf的文件，该文件是一个自文档化的示例配置文件，
您可以使用它来配置sentinel，但是典型的最小配置文件如下所示：

    sentinel monitor mymaster 127.0.0.1 6379 2
    sentinel down-after-milliseconds mymaster 60000
    sentinel failover-timeout mymaster 180000
    sentinel parallel-syncs mymaster 1
    
    sentinel monitor resque 192.168.1.3 6380 4
    sentinel down-after-milliseconds resque 10000
    sentinel failover-timeout resque 180000
    sentinel parallel-syncs resque 5

您只需要指定要监视的主机，为每个分离的主机（可能有任意数量的从机）指定不同的名称。
不需要指定从机，它们是自动发现的。Sentinel将自动更新配置，并提供有关从属服务器的附加信息（以便在重新启动时保留这些信息）。
每次在故障转移期间从设备升级到主设备，每次发现新的哨兵时，也会重写配置。

上面的示例配置基本上监视两组KeyDB实例，每个实例由一个主实例和一个未定义数量的从实例组成。
一组实例称为mymaster，另一组称为resque。

sentinel monitor语句参数的含义如下：

sentinel monitor <master-group-name> <ip> <port> <quorum>

为了清楚起见，让我们逐行检查配置选项的含义：

第一行用于告诉KeyDB监视名为mymaster的主机，即位于地址127.0.0.1和端口6379的主机，仲裁数为2。
一切都很明显，但法定人数的争论：

quorum是需要就主服务器不可访问这一事实达成一致的哨兵数量，以便真正将从服务器标记为失败，
并最终在可能的情况下启动故障转移过程。

但是，仲裁仅用于检测故障。为了实际执行故障转移，其中一个哨兵需要被选为故障转移的领导者并被授权继续。
这只发生在大多数哨兵进程的投票上。

例如，如果您有5个Sentinel进程，并且给定主服务器的仲裁设置为2，则会发生以下情况：

* 如果两个哨兵同时同意无法访问主服务器，其中一个哨兵将尝试启动故障转移。
* 如果至少有三个哨兵可以到达，故障转移将被授权并实际启动。

实际上，这意味着在发生故障时，如果大多数Sentinel进程无法对话，Sentinel将永远不会启动故障转移（也就是说，少数分区中没有故障转移）。

## 其他Sentinel选项

其他选项几乎都是这样的：

    sentinel <option_name> <master_name> <option_value>

并用于以下目的：

* down-after-millishes是以毫秒为单位的时间，对于开始认为实例已关闭的哨兵来说，实例不应可访问（要么不响应PINGs，要么它正在用错误进行响应）。
* parallel syncs设置可在故障转移后同时重新配置以使用新主机的从机数量。数目越小，故障转移过程完成所需的时间就越长，
但是，如果将从属服务器配置为提供旧数据，则可能不希望所有从属服务器同时与主服务器重新同步。
虽然对于从机来说，复制过程基本上是非阻塞的，但有时它会停止从主机加载大容量数据。
通过将此选项设置为值1，可以确保一次只能访问一个slave服务器。

其他选项在本文的其余部分中进行了描述，并在KeyDB发行版附带的示例sentinel.conf文件中进行了说明。

所有配置参数都可以在运行时使用SENTINEL SET命令进行修改。有关更多信息，请参见运行时**重新配置标记**。

## Sentinel部署示例

现在您已经了解了有关标记的基本信息，您可能想知道应该将标记进程放置在何处，需要多少标记进程等等。本节展示一些示例部署。

我们使用ASCII艺术，以图形格式向您展示配置示例，这就是不同符号的含义:

+--------------------+
| This is a computer |
| or VM that fails   |
| independently. We  |
| call it a "box"    |
+--------------------+

我们在盒子里写上他们正在运行的东西:

+-------------------+
| KeyDB master M1   |
| KeyDB Sentinel S1 |
+-------------------+

不同的盒子用线条连接，表示它们会说话:

+-------------+               +-------------+
| Sentinel S1 |---------------| Sentinel S2 |
+-------------+               +-------------+

网络分区显示为使用斜线的中断线:

+-------------+                +-------------+
| Sentinel S1 |------ // ------| Sentinel S2 |
+-------------+                +-------------+

还要注意:

* master被称为M1, M2, M3，…、Mn。

* slave被称为R1, R2, R3，…， Rn (R代表replica副本)。

* Sentinels被称为S1, S2, S3，…,Sn。

* client被称为C1, C2, C3，…Cn。

* 当一个实例由于Sentinels操作而改变角色时，我们将它放在方括号中，因此[M1]意味着一个实例现在由于Sentinels干预而成为一个master实例。

请注意，我们将永远不会显示仅使用两个Sentinels的设置，因为Sentinels总是需要与大多数人交谈才能开始故障转移。

## 示例1：只有两个Sentinel，不要这样做

    +----+         +----+
    | M1 |---------| R1 |
    | S1 |         | S2 |
    +----+         +----+
    
    Configuration: quorum = 1

* 在这个设置中，如果主M1失败，R1将被提升，因为两个哨兵可以就失败达成一致(显然将quorum设置为1)，还可以授权进行故障转移，
因为大多数是2。所以很明显，表面上它可以工作，然而，检查下一点，看看为什么这个设置是坏的。

* 如果运行M1的box停止工作，那么S1也停止工作。在另一个机器S2中运行的标记将无法授权故障转移，因此系统将不可用。

请注意，为了安排不同的故障转移，需要多数配置，然后将最新配置传播给所有Sentinels。还要注意，在没有任何协议的情况下，
在上述设置的单个端进行故障转移的能力是非常危险的:

    +----+           +------+
    | M1 |----//-----| [M1] |
    | S1 |           | S2   |
    +----+           +------+

在上面的配置中，我们以完全对称的方式创建了两个主机(假设S2可以在没有授权的情况下进行故障转移)。
client端可能会无限期地向两边写入数据，而且无法理解何时分区会修复正确的配置，以防止永久性的脑裂状况。

所以**请在三个不同的box里部署至少三个哨兵**。


## 示例2：三个boxes的基本设置

这是一个非常简单的设置，它的优点是易于调优以获得额外的安全性。它基于三个机器，每个机器运行一个KeyDB进程和一个Sentinel进程。

           +----+
           | M1 |
           | S1 |
           +----+
              |
    +----+    |    +----+
    | R2 |----+----| R3 |
    | S2 |         | S3 |
    +----+         +----+
    
    Configuration: quorum = 2

如果主M1失败，则S2和S3将对失败达成一致，并将能够授权故障转移，从而使客户端能够继续。

在每一个哨点设置中，KeyDB异步复制，总是存在丢失一些写的风险，因为一个给定的已确认的写可能无法到达被提升为master进程的从进程。
但是，在上面的设置中，由于客户端与旧master服务器隔离，因此存在较高的风险，如下图所示:

             +----+
             | M1 |
             | S1 | <- C1 (writes will be lost)
             +----+
                |
                /
                /
    +------+    |    +----+
    | [M2] |----+----| R3 |
    | S2   |         | S3 |
    +------+         +----+


在这种情况下，一个网络分区隔离了旧的master M1，因此从R2被提升为master。但是，与旧master服务器在同一分区中的客户端(如C1)可以继续向旧master服务器写入数据。
这个数据将永远丢失，因为当分区恢复时，master服务器将被重新配置为新master服务器的一个slave，丢弃它的数据集。

可以使用以下KeyDB复制特性来缓解这个问题，该特性允许在master服务器检测到无法将写操作转移到指定数量的slave服务器时停止接受写操作。

    min-slaves-to-write 1
    min-slaves-max-lag 10

通过上面的配置(请参阅KeyDB发行版中的自注释redis.conf示例以获得更多信息)，KeyDB实例在充当master实例时，
如果不能向至少一个slave实例进行写操作，则将停止接受写操作。由于复制是异步的，因此不能写实际上意味着slave服务器要么断开连接，
要么在超过指定的最大延迟秒数的时间内没有向我们发送异步确认。

使用上面示例中的旧KeyDB主M1配置，10秒后将不可用。当分区恢复后，标记配置将收敛到新的配置，客户端C1将能够获取有效的配置并继续使用新的master服务器。

然而，天下没有免费的午餐。有了这种细化，如果两个slave 挂掉了，master将停止接受写操作。这是一种权衡。

## 示例3：客户端框中的Sentinel

有时，我们只有两个KeyDB盒可用，一个用于master服务器，一个用于slave服务器。在这种情况下，示例2中的配置是不可行的，因此我们可以采用以下方法，即在client所在的位置放置Sentinels:

            +----+         +----+
            | M1 |----+----| R1 |
            |    |    |    |    |
            +----+    |    +----+
                      |
         +------------+------------+
         |            |            |
         |            |            |
      +----+        +----+      +----+
      | C1 |        | C2 |      | C3 |
      | S1 |        | S2 |      | S3 |
      +----+        +----+      +----+

      Configuration: quorum = 2

在此设置中，Sentinels的观点与client相同:如果大多数client都可以访问master服务器，那就没问题。
这里的C1、C2、C3是通用client，这并不意味着C1标识了连接到KeyDB的单个client。它更像是应用服务器、Rails应用程序或类似的东西。

如果运行M1和S1的机器发生故障，故障转移将不会出现问题，但是很容易看到不同的网络分区将导致不同的行为。
例如，如果client和KeyDB服务器之间的网络断开连接，则Sentinel将无法进行设置，因为KeyDB master服务器和slave服务器都不可用。

注意,如果C3分区与M1(与上面描述的网络几乎不可能的,但可能性更大可能有不同的布局,或者因为失败的软件层),我们有一个类似的问题如例2所述,
不同,我们没有办法打破对称,因为只有一个slave和master,所以master不能停止接受查询时断开它的slave,否则master永远可以在slave失败。

这是一个有效的设置,但设置示例2的优势如KeyDB HA系统运行在相同的盒子KeyDB本身可能是简单的管理,
并能对master的时间约束到少数分区可以接收写道。      
      
## 示例4：少于三个客户端的Sentinel客户端

如果client没有足够的3个机器(例如3个web服务器)，则无法使用示例3中描述的设置。
在这种情况下，我们需要采取以下混合设置:

            +----+         +----+
            | M1 |----+----| R1 |
            | S1 |    |    | S2 |
            +----+    |    +----+
                      |
               +------+-----+
               |            |  
               |            |
            +----+        +----+
            | C1 |        | C2 |
            | S3 |        | S4 |
            +----+        +----+

      Configuration: quorum = 3

这与示例3中的设置类似，但在这里，我们在四个可用的box中运行四个Sentinels。如果master M1不可用，其他三个Sentinels将执行故障转移。
如果在应用层中没有高可用性
从理论上讲，这种设置可以删除C2和S4运行的方框，并将quorum设置为2。但是，，我们不太可能希望在KeyDB端使用HA。

## Sentinel, Docker, NAT, 和 可能的问题 

Docker使用了一种称为端口映射的技术:在Docker容器中运行的程序可能与它认为正在使用的端口不同。
这对于在同一台服务器上同时运行多个使用相同端口的容器非常有用。

Docker并不是发生这种情况的唯一软件系统，还有其他网络地址转换设置，
其中端口可以重新映射，有时不是端口，而是IP地址。

重新映射端口和地址会以两种方式产生问题:

1.Sentinel对其他Sentinels的自动发现不再起作用，因为它是基于hello消息的，
每个Sentinel在hello消息中声明它们正在监听哪个端口和IP地址的连接。
然而，Sentinel无法理解一个地址或端口被重新映射，因此它宣布的信息对其他Sentinel来说是不正确的。

2.slave在KeyDB master的INFO输出中以类似的方式列出:地址由检查TCP连接的远程对等点的主机检测到，而端口则在握手期间由slave自己通知，
然而，端口可能会因为与point 1相同的原因而出错。

因为Sentinels自动检测slave使用master INFO输出信息,发现slave不可达,master和Sentinel将永远无法故障转移,从系统的角度因为没有好slave,
因此，目前无法使用Docker部署的Sentinel来监视一组master实例和slave实例, 除非你指示Docker 1:1 映射端口。

对于第一个问题,如果您想运行一组Sentinel实例使用Docker和转发端口(或任何其他NAT设置端口重新映射),
您可以使用以下两个Sentine配置指示为了强制Sentine宣布一组特定的IP和端口:

    sentinel announce-ip <ip>
    sentinel announce-port <port>

注意，Docker可以在主机联网模式下运行(有关更多信息，请检查--net=host选项)。这应该不会产生任何问题，因为在这个设置中没有重新映射端口。

## 快速教程

在本文档的下一节中，将逐步介绍关于Sentinel API、配置和语义的所有细节。
然而，对于那些希望尽快使用系统的人来说，本节是一个教程，展示了如何配置和与3个Sentinel实例交互。

这里我们假设实例在端口5000、5001、5002处执行。我们还假设在端口6379上有一个运行的KeyDB主服务器，而在端口6380上有一个从服务器。在本教程中，我们将使用IPv4环回地址127.0.0.1，假设您在您的个人计算机上运行模拟。

这三个Sentinel配置文件应该如下图所示:

    port 5000
    sentinel monitor mymaster 127.0.0.1 6379 2
    sentinel down-after-milliseconds mymaster 5000
    sentinel failover-timeout mymaster 60000
    sentinel parallel-syncs mymaster 1

其他两个配置文件是相同的，但是使用5001和5002作为端口号。

关于上面的配置，有几点需要注意:

* master叫做mymaster。它标识了master和它的slave。由于每个master有不同的名称，所以Sentinel可以同时监视不同的master和slave。
* quorum仲裁被设置为值2(sentinel监视器配置指令的最后一个参数)。
* down-after-milliseconds是5000毫秒，也就是5秒，所以一旦我们在这段时间内没有收到来自ping的任何回复，
master将被检测为失败。

一旦你启动这三个Sentinel，你会看到他们记录的一些信息，比如:

    +monitor master mymaster 127.0.0.1 6379 quorum 2

这是一个Sentinel事件，如果您订阅了稍后指定的事件名称，则可以通过Pub/Sub接收此类事件。

在故障检测和故障转移期间，Sentinel生成并记录不同的事件。

## 询问Sentinel master的状况

在开始使用Sentinel时，最明显的做法是检查它所监控的master服务器是否运行良好:

        $ keydb-cli -p 5000
        127.0.0.1:5000> sentinel master mymaster
         1) "name"
         2) "mymaster"
         3) "ip"
         4) "127.0.0.1"
         5) "port"
         6) "6379"
         7) "runid"
         8) "953ae6a589449c13ddefaee3538d356d287f509b"
         9) "flags"
        10) "master"
        11) "link-pending-commands"
        12) "0"
        13) "link-refcount"
        14) "1"
        15) "last-ping-sent"
        16) "0"
        17) "last-ok-ping-reply"
        18) "735"
        19) "last-ping-reply"
        20) "735"
        21) "down-after-milliseconds"
        22) "5000"
        23) "info-refresh"
        24) "126"
        25) "role-reported"
        26) "master"
        27) "role-reported-time"
        28) "532439"
        29) "config-epoch"
        30) "1"
        31) "num-slaves"
        32) "1"
        33) "num-other-sentinels"
        34) "2"
        35) "quorum"
        36) "2"
        37) "failover-timeout"
        38) "60000"
        39) "parallel-syncs"
        40) "1"

如您所见，它打印了大量关于master的信息。其中有一些是我们特别感兴趣的:

1.num-other-sentinels 是2，所以我们知道sentinel已经为这个master检测了2个sentinels。如果检查日志，您将看到生成的 +sentinel 事件。

2.flags就是master。如果master服务器宕机，我们可以在这里看到s_down或o_down标志。

3.num-slaves 被正确地设置为1，所以哨兵也检测到有一个附加的奴隶到我们的主人。

为了了解更多关于这个实例，您可能想尝试以下两个命令:

    SENTINEL slaves mymaster
    SENTINEL sentinels mymaster

第一个将提供关于与master相连的slave的类似信息，第二个将提供关于其他sentinels的信息。

## 获取当前master的地址

正如我们已经指定的，Sentinel还充当想要连接到一组master服务器和slave服务器的客户端的配置提供者。
由于可能会出现故障转移或重新配置，client不知道对于给定的一组实例，谁是当前活动active的master用户，所以Sentinel导出一个API来询问这个问题:

    127.0.0.1:5000> SENTINEL get-master-addr-by-name mymaster
    1) "127.0.0.1"
    2) "6379"

## 测试故障转移

在这一点上，我们的玩具Sentinel部署准备测试。我们可以杀死我们的主进程并检查配置是否改变。我们可以这样做:

    keydb-cli -p 6379 DEBUG sleep 30

此命令将使我们的master服务器不再可及，休眠30秒。它基本上模拟了由于某种原因挂起的master服务器。

如果你检查Sentinel日志，你应该可以看到很多动作:

1.每个Sentinel检测到主节点的+sdown事件。
2.这个事件后来被升级为+odown，这意味着多个Sentinel都认为master节点是不可到达的。
3.Sentinel投票给将开始第一次故障转移尝试的Sentinel。
4.故障转移发生。

如果你再次问我的master当前的master地址是什么，最终我们应该会得到一个不同的回复:

    127.0.0.1:5000> SENTINEL get-master-addr-by-name mymaster
    1) "127.0.0.1"
    2) "6380"

到目前为止一切顺利……此时，您可以跳转到创建Sentinel部署，或者阅读更多内容以了解所有Sentinel命令和内部机制。

# Sentinel API

Sentinel提供了一个API来检查其状态，检查被监控的masetr和slave的健康状况，订阅以接收特定的通知，并在运行时更改Sentinel的配置。

默认情况下，Sentinel使用TCP端口26379运行(注意6379是正常的KeyDB端口)。Sentinel使用KeyDB协议接受命令，因此您可以使用keydb-cli 或 任何其他未修改的KeyDB客户端来与Sentinel通信。

可以直接查询Sentinel，从它的角度检查被监视的KeyDB实例的状态，查看它知道的其他Sentinel等等。或者，使用Pub/Sub，每当发生故障转移或实例输入错误条件等事件时，就可以从Sentinel接收推送样式通知。

## Sentinel 命令

下面是一个可接受的命令列表，不包括用于修改标记配置的命令，稍后将讨论这些命令。

* **PING** 这个命令只会返回PONG。

* **SENTINEL masters** 显示一份监控master的名单和他们的状态。

* **SENTINEL master <master name>** 显示指定主机的状态和信息。

* **SENTINEL slaves <master name>** 显示此master的slave列表及其状态。

* **SENTINEL sentinels <master name>** 显示了这个master的哨兵实例列表及其状态。

* **SENTINEL get-master-addr-by-name  <master name>** 返回主机的ip和端口号。如果此master服务器的故障转移正在进行或已成功终止，它将返回提升的slave服务器的地址和端口。

* **SENTINEL reset <pattern>** 此命令将重置所有具有匹配名称的master节点。模式参数是一个全局样式的模式。复位过程清除主进程中任何以前的状态(包括正在进行的故障转移)，并删除已经发现并与主进程关联的每个从属和标记。

* **SENTINEL failover <master name>** 强制进行故障转移，就好像master节点无法到达一样，并且没有请求其他岗哨的同意(但是将发布配置的新版本，以便其他岗哨更新其配置)。

* **SENTINEL ckquorum <master name>** 检查当前的哨兵配置是否能够达到master服务器故障转移所需的仲裁，以及授权故障转移所需的多数仲裁。此命令应用于监视系统，以检查Sentinel部署是否正常。

* **SENTINEL flushconfig** 强制SENTINEL重写其在磁盘上的配置，包括当前的SENTINEL状态。通常，每当状态发生变化时，Sentinel都会重写配置(在重启时持久化到磁盘上的状态子集的上下文中)。但是，有时可能由于操作错误、磁盘故障、包升级脚本或配置管理器而丢失配置文件。
在这些情况下，迫使Sentinel重写配置文件的方法非常方便。即使完全没有前面的配置文件，这个命令也可以工作。


## 在运行时重新配置Sentinel

从KeyDB版本2.8.4开始，Sentinel提供了一个API来添加、删除或更改给定主机的配置。注意，如果您有多个Sentinel，您应该将这些更改应用到所有实例中，以便KeyDB Sentinel正常工作。这意味着改变单个Sentinel的配置并不会自动将这些改变传播到网络中的其他Sentinel。

以下是用于更新Sentinel实例配置的Sentinel子命令列表

* **SENTINEL MONITOR <name> <ip> <port> <quorum>** 此命令告诉Sentinel开始监视具有指定名称、ip、端口和仲裁的新主机。它与sentinel.conf配置文件中的sentinel monitor配置指令相同，不同之处在于您不能在ip中使用主机名，但您需要提供IPv4或IPv6地址。

* **SENTINEL REMOVE <name>** 用于移除指定的master服务器: master服务器将不再被监控，并将完全从Sentinel的内部状态移除，因此它将不再被Sentinel master服务器列出等等。

* **SENTINEL SET <name> <option> <value>** SET命令与KeyDB的CONFIG SET命令非常相似，用于更改特定主机的配置参数。可以指定多个 选项 / 值对(或者根本不指定)。可以通过sentinel.conf配置的所有配置参数也可以使用SET命令进行配置。

下面是一个为了修改名为objects-cache的down-after-milliseconds配置的Sentinel集命令示例:

	SENTINEL SET objects-cache-master down-after-milliseconds 1000

如前所述，可以使用SENTINEL SET 启动配置文件中可设置的所有配置参数。此外，可以只更改master仲裁配置，而不需要删除和重新添加master仲裁，并在SENTINEL REMOVE 后再添加SENTINEL MONITOR，但只需使用以下命令:

	SENTINEL SET objects-cache-master quorum 5

注意，这里没有等效的GET命令，因为SENTINEL MASTER以简单的解析格式(作为field/value对数组)提供了所有配置参数。

## 添加或删除哨兵

向部署中添加新Sentinel是一个简单的过程，因为Sentinel实现了自动发现机制。您所需要做的就是启动配置为监视当前活动主机的新Sentinel。
在10秒内，Sentinels将获得其他Sentinel的名单和一组附属于master的slave。

如果您需要同时添加多个Sentinel，建议一个接一个地添加，等待所有其他Sentinel在添加下一个之前已经知道第一个Sentinel。
这是有用的，以确保大多数仍然可以实现只在一边的一个分区，在偶然故障应该发生的过程中添加新的Sentinel。

这可以通过添加每一个延迟30秒的新Sentinel和在没有网络分区的情况下很容易实现。

在这个过程的最后，可以使用Sentinel master的名字来检查所有Sentinel是否同意监视master的Sentinel总数。

删除Sentinel稍微复杂一点:Sentinel永远不会忘记已经见过的Sentinel，即使它们很长时间都无法到达，
因为我们不想动态地更改大多数需要授权故障转移和创建新配置号的内容。因此，为了删除Sentinel，应该在没有网络分区的情况下执行以下步骤:

1.停止要移除的Sentinel的Sentinel过程。
2.发送一个SENTINEL RESET *命令到所有其他Sentinel实例(如果您只想重置一个master实例，可以使用精确的master实例名来代替 *)。一个接一个，在实例之间至少等待30秒。
3.检查所有的Sentinel同意当前活动的Sentinel的数量，通过检查每个输出SENTINEL MASTER mastername。

## 删除旧的master服务器或无法访问的slave服务器

Sentinels永远不会忘记某个master的slave，即使他们长时间无法到达。这很有用，因为Sentinels应该能够在网络分区或故障事件之后正确地重新配置返回的slave服务器。

此外，在故障转移之后，故障转移master服务器实际上被添加为新master服务器的一个slave，通过这种方式，
它将被重新配置，以便在新master服务器再次可用时立即复制它。

然而，有时你想永远从Sentinels监视的slave名单中除去一个slave(可能是老master)。

为了做到这一点，你需要发送一个SENTINEL RESET mastername命令给所有的Sentinels: 它们将在接下来的10秒内刷新slave列表，
只添加当前master INFO输出中正确复制的那些。

## Pub/Sub 消息

client可以使用Sentinel，因为它是与KeyDB兼容的Pub/Sub服务器(但不能使用PUBLISH)，
以便订阅或订阅频道并获得关于特定事件的通知。

通道名称与事件名称相同。例如，名为+sdown的通道将接收与进入SDOWN的实例相关的所有通知(SDOWN意味着从您正在查询的标记的角度来看，该实例不再是可访问的)。

要获取所有消息，只需使用PSUBSCRIBE *进行订阅。

以下是使用此API可以接收的通道和消息格式列表。第一个单词是channel/event名称，其余是数据格式。

注:如果指定了实例细节，则表示提供了以下参数来标识目标实例:

    <instance-type> <name> <ip> <port> @ <master-name> <master-ip> <master-port>

标识master的部分(从@参数到结束)是可选的，仅在实例本身不是master时才指定。

* +reset-master <instance details> -- master服务器被重新设置
* +slave <instance details> -- 发现并连接了一个新slave
* +failover-state-reconf-slaves <instance details> -- 故障转移状态更改为 reconf-slaves 状态
* +failover-detected <instance details> -- 检测到由另一个标记或任何其他外部实体启动的故障转移(一个连接的slave节点变为一个master节点)。
* +slave-reconf-sent <instance details> --  leader sentinel 发送SLAVEOF给这个实例,以便为新的slave重新配置它
* +slave-reconf-inprog <instance details> -- 重新配置slave显示为新master ip:port对的slave，但同步过程尚未完成。
* +slave-reconf-done <instance details> -- slave现在与新master同步。
* -dup-sentinel <instance details> -- 指定主机的一个或多个Sentinels已作为重复项删除（例如，当Sentinel实例重新启动时会发生这种情况）。
* +sentinel <instance details> -- 检测到并附加了此master的新Sentinel。
* +sdown <instance details> -- 指定的实例现在处于主观关闭状态
* -sdown <instance details> -- 指定的实例不再处于主观关闭状态
* +odown <instance details> -- 指定的实例现在处于客观关闭状态
* -odown <instance details> -- 指定的实例不再处于客观关闭状态
* +new-epoch <instance details> -- 当前epoch已更新
* +try-failover <instance details> -- 正在进行新的故障转移，等待大多数人选择。
* +elected-leader <instance details> -- 赢得指定时代的选举，可以进行故障转移。
* +failover-state-select-slave <instance details> -- 新的故障转移状态是select-slave：我们正在试图找到一个适合提升的slave。
* no-good-slave <instance details> -- 没有好的slave可以提升。目前，我们将在一段时间后尝试，但这可能会改变，状态机在这种情况下将完全中止故障转移。
* selected-slave <instance details> -- 我们找到了要升级的指定的好slave。
* failover-state-send-slaveof-noone <instance details> -- 我们正在尝试将提升的slave服务器重新配置为master服务器，等待其切换。
* failover-end-for-timeout <instance details> -- 故障转移因超时而终止，slave最终仍将配置为与新master进行复制。
* failover-end <instance details> -- 故障转移成功终止。所有的slave似乎都被重新配置为使用新的master进行复制。
* switch-master <master name> <oldip> <oldport> <newip> <newport> -- master新IP和地址是配置更改后指定的IP和地址。这是大多数外部用户感兴趣的消息
* +tilt -- 倾斜模式进入
* -tilt -- 倾斜模式退出

## -BUSY 状态实现

当Lua脚本运行的时间超过配置的Lua脚本时间限制时，KeyDB实例返回-BUSY错误。在触发故障转移之前发生这种情况时，
KeyDB Sentinel将尝试发送脚本KILL命令，只有在脚本为read-only时才会成功。

如果此尝试之后实例仍处于错误状态，则它最终将被故障转移。

## slave 优先级

KeyDB实例有一个名为slave-priority的配置参数。此信息由KeyDB slave实例在其信息输出中公开，
Sentinel使用此信息在可用于故障转移主服务器的实例中选择一个slave服务器：

1.如果slave priority设置为0，则slave永远不会升级为主机。
2.Sentinel优先选择优先级较低的slave。

例如，如果当前master的同一个数据中心中有一个slave S1，而另一个数据中心中有另一个slave S2，则可以设置优先级为10的S1和优先级为100的S2，这样，如果master发生故障，并且S1和S2都可用，则优先选择S1。

有关slave选择方式的更多信息，请查看本文档的slave选择和优先级部分。

## Sentinel 和 KeyDB身份验证

当master被配置为需要来自client的密码时，作为安全措施，slave服务器还需要知道此密码，以便向master服务器进行身份验证并创建用于异步复制协议的M-S连接。

这是通过使用以下配置指令实现的：

* 在master中设置requirepass，以设置身份验证密码，并确保实例不会处理对未经身份验证的client的请求。
* slave中的masterauth，以便slave与master进行身份验证，以便slave中正确复制数据。

当使用Sentinel时，没有一个master服务器，因为在故障转移之后，slave服务器可能扮演master服务器的角色，并且旧的master服务器可以重新配置以充当slave服务器，所以您要做的是在所有实例中设置上述指令，包括master服务器和slave服务器。

这通常也是一个正常的设置，因为您不希望只在master服务器中保护数据，而在slave服务器中可以访问相同的数据。

但是，在不常见的情况下，如果您需要一个不需要身份验证就可以访问的slave，您仍然可以通过设置slave优先级为零来执行此操作，以防止此slave升级为master，并且在该slave中只配置masterauth指令，而不使用requirepass指令，这样未经验证的客户端就可以读取数据。

为使Sentinel在配置为requirepass时连接到KeyDB服务器实例，Sentinel配置必须包含Sentinel auth-pass指令，格式如下：

    sentinel auth-pass <master-group-name> <pass>
   
## 使用身份验证配置Sentinel实例

您还可以配置Sentinel实例本身，以便通过AUTH命令要求客户端身份验证，但是此功能仅从KeyDB 5.0.1开始可用。

为此，只需向所有Sentinel实例添加以下配置指令：

    requirepass "your_password_here"

当这样配置时，Sentinel将做两件事：

1.client需要密码才能向Sentinel发送命令。这是显而易见的，因为这样的配置指令通常在KeyDB中工作。
2.此外，此Sentinel实例将使用配置为访问本地Sentinel的相同密码，以便对其连接到的所有其他Sentinel实例进行身份验证。

这意味着**您必须在所有Sentinel实例中配置相同的requirepass密码**。这样，每个Sentinel都可以与其他Sentinel通话，而无需为每个Sentinel配置访问所有其他Sentinel的密码，这将非常不切实际。

在使用此配置之前，请确保client库能够将AUTH命令发送到Sentinel实例

## Sentinel客户端实现

Sentinel需要显式的客户端支持，除非系统配置为执行一个脚本，该脚本将所有请求透明重定向到新的master实例（虚拟IP或其他类似系统）。
client库实现的主题在文档Sentinel client指南中介绍。

# 更先进的概念

在下面的部分中，我们将介绍一些有关Sentinel如何工作的细节，而不必求助于本文档最后一部分将介绍的实现细节和算法。

## SDOWN和ODOWN故障状态

KeyDB Sentinel有两个不同的关闭概念，一个被称为主观关闭条件（SDOWN），另一个是给定Sentinel实例的本地关闭条件。
另一种被称为客观下降条件（ODOWN），当足够多的哨兵（至少配置为被监控主机的仲裁参数的数字）具有SDOWN条件，并使用SENTINEL is master Down by addr命令从其他哨兵处获得反馈时达到。

从Sentinel的角度来看，如果在配置 is-master-down-after-milliseconds参数中指定的秒数内没有收到对PING请求的有效回复，
则会达到SDOWN条件。

对PING的可接受答复如下：

* PING用+PONG回复。
* PING以-LOADING错误回复。
* PING以-MASTERDOWN错误回复。

任何其他回复（或根本没有回复）都被视为无效。但是请注意, **在INFO输出中将自己作为slave播发的逻辑master被认为已关闭**。

请注意，SDOWN要求在配置的整个时间间隔内都不接收可接受的回复，因此，例如，如果时间间隔为30000毫秒（30秒），并且我们每29秒接收一个可接受的ping回复，则认为该实例正在工作。

SDOWN不足以触发故障转移：它只意味着单个Sentinel认为KeyDB实例不可用。要触发故障转移，必须达到ODOWN状态。

要从SDOWN切换到ODOWN，没有使用强一致性算法，而只是gossip的一种形式：如果一个给定的Sentinels得到报告说，在给定的时间范围内，一个master没有从足够的Sentinels那里工作，SDOWN将被提升为ODOWN。如果此确认稍后丢失，则清除标志。

为了真正启动故障转移，需要使用实际多数的更严格的授权，但如果不达到ODOWN状态，则无法触发任何故障转移。

ODOWN条件只适用于master。对于其他类型的情况，Sentinels不需要行动，所以slave和其他Sentinel永远不会达到"ODOWN"状态，但只有"SDOWN"才是。

然而，SDOWN也有语义含义。例如，处于SDOWN状态的slave服务器未被执行故障转移的Sentinel选择升级。

## Sentinel和slave自动发现

Sentinels 与其他Sentinels保持联系，以便相互检查对方的可用性，并交换消息。
但是，您不需要在运行的每个Sentinel实例中配置其他Sentinel地址的列表，因为Sentinel使用KeyDB instances Pub/Sub功能来发现监视相同master和slave的其他Sentinel。

此功能是通过向名为"hello sentinel"的频道发送hello消息来实现的。

类似地，您不需要配置连接到master服务器的slave服务器列表，因为Sentinel将自动发现这个查询KeyDB的列表。

* 每个Sentinel 每隔两秒钟向每个受监视的master/slave Pub/Sub channel __sentinel__:hello，用ip，port，runid宣布它的存在。
* 每个Sentinel都订阅了Pub/Sub channel __sentinel__:hello对于每个master和slave 寻找未知的哨兵。当新的Sentinel被检测到时，他们被添加为这个master的Sentinel。
* Hello消息还包括master服务器的完整当前配置。如果接收sentinel对给定master的配置比接收到的旧，它会立即更新到新配置。
* 在将新的sentinel添加到master服务器之前，sentinel总是检查是否已经存在具有相同runid或相同地址（ip和端口对）的sentinel。
在这种情况下，所有匹配的sentinel被移除，新的sentinel被添加。

## 故障转移过程之外实例的Sentinel重新配置

即使没有进行故障转移，Sentinels也将始终尝试在受监视的实例上设置当前配置。明确地：

声称是master服务器的slave服务器（根据当前配置）将配置为要与当前master服务器进行复制的slave服务器。

* 连接到错误master服务器的slave服务器将被重新配置为使用正确的master服务器进行复制。
* Sentinels要重新配置slave，必须观察错误的配置一段时间，即大于用于广播新配置的周期。

这可以防止配置过时的Sentinels（例如，因为他们刚从分区重新加入）在接收更新之前尝试更改slave配置。

还要注意，总是尝试强制使用当前配置的语义如何使故障转移对分区更具抵抗力：

* 当master返回可用时，故障转移将重新配置为slave。
* 在分区期间被分区的slave在可到达时重新配置。

关于本节要记住的重要一课是：**Sentinel是一个系统，在这个系统中，每个进程总是试图将最后一个逻辑配置强加于被监视的实例集**。

## slave选择和优先级


当Sentinel实例准备执行故障转移时，由于master处于ODOWN状态，并且Sentinel从大多数已知的Sentinel实例接收到故障转移授权，因此需要选择合适的slave。

slave选择过程评估有关slave的以下信息：

1.与master断开的时间。
2.slave 优先级。
3.已处理复制偏移量。
4.Run ID。

如果发现slave与master断开连接的时间超过配置的主超时时间（down-after-milliseconds 选项）的十倍，加上slave执行故障转移的哨兵的角度来看master也不可用的时间，则认为该slave不适合进行故障转移并被跳过。

更严格地说，一个slave，其INFO输出建议与master断开的时间超过：

    (down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state

被认为是不可靠的并且被完全忽视。

slave选择只考虑通过上述测试的slave，并根据上述条件按以下顺序对其排序。

1.slave按KeyDB实例的redis.conf文件中配置slave-priority排序。优先考虑较低的优先级。

2.如果优先级相同，则检查slave处理的复制偏移量，并选择slave接收更多数据的slave。

3.如果多个slave具有相同的优先级，并处理与master数据相同的数据，则执行进一步的检查，从字典上选择较小的运行ID来选择slave。
具有较低的运行ID对于slave者来说不是真正的优势，但有用的是使slave选择的过程更具确定性。而不是选择一个随机的slave。

KeyDB master服务器（在故障转移后可以转换为slave服务器）和slave服务器，如果有强烈首选的计算机，则都必须配置slave-priority。
否则，所有实例都可以使用默认的运行ID运行（这是建议的设置，因为按复制偏移量选择slave要有趣得多）。

KeyDB实例可以配置一个特殊的slave-priority为零，这样Sentinels就不会选择KeyDB实例作为新的master服务器。然而，以这种方式配置的slave仍将由Sentinels重新配置，
以便在故障转移后与新的master进行复制，唯一的区别是它永远不会成为master本身。

# 算法和内部

在下面的章节中，我们将探讨Sentinel行为的细节。用户并不需要知道所有的细节，但是对Sentinel的深入了解有助于更有效地部署和操作Sentinel。

## Quorum仲裁 

前面的部分显示，Sentinel监视的每个master服务器都与配置的仲裁关联。它指定需要就master服务器的不可访问性或错误条件达成一致以触发故障转移的Sentinel进程数。

但是，在触发故障转移之后，为了实际执行故障转移，**至少大多数Sentinel必须授权Sentinel进行故障转移**。Sentinel永远不会在有少数Sentinel存在的分区中执行故障转移。

让我们试着把事情说清楚一点：

* Quorum：需要检测错误条件以将主进程标记为ODOWN的Sentinel进程数。
* 故障转移由ODOWN状态触发。
* 一旦触发故障转移，尝试故障转移的Sentinel需要请求对大多数Sentinel的授权（如果仲裁设置为大于多数Sentinel的数字，则请求对多数Sentinel的授权）。

这种差异看似微妙，但实际上很容易理解和使用。例如，如果您有5个Sentinel实例，并且quorum设置为2，那么只要2个Sentinel认为master服务器不可访问，就会触发故障转移，但是，只有当两个Sentinel中的一个至少从3个Sentinel获得授权时，它才能进行故障转移。

如果将仲裁配置为5，则所有sentinel必须同意master错误条件，并且需要所有sentinel的授权才能进行故障转移。

这意味着quorum可以通过两种方式用于调整Sentinel：

1.如果将quorum设置为小于我们部署的大多数Sentinel的值，则基本上会使Sentinel对master服务器故障更加敏感，只要只有少数Sentinel无法再与master服务器对话，就会触发故障转移。
2.如果将仲裁设置为大于大多数哨兵的值，则仅当存在大量（大于大多数）连接良好的Sentinel同意master服务器关闭时，我们才使哨兵能够进行故障转移。

## epochs配置

Sentinel需要获得多数人的授权才能启动故障转移，原因如下：

当一个Sentinel被授权时，它将为它正在故障转移的主机获得一个唯一的配置epoch纪元。此数字将用于在故障转移完成后版本新配置。
因为大多数人都同意某个给定的版本被分配给某个给定的哨兵，所以没有其他Sentinel能够使用它。这意味着每个故障转移的每个配置都有一个唯一的版本。
我们会明白为什么这很重要。

此外，Sentinel还有一个规则：如果一个Sentinel投票给另一个Sentinel进行给定master服务器的故障转移，它将等待一段时间尝试再次对同一个master服务器进行故障转移。
此延迟是您可以在sentinel.conf中配置的故障转移超时时间。这意味着sentinel不会尝试同时故障转移同一主机，首先请求授权的将尝试，如果失败，则另一个将在一段时间后重试，以此类推。

KeyDB Sentinel保证了liveness属性，如果大多数Sentinel都能说话，那么在master服务器关闭时，最终将授权一个Sentinel进行故障转移。

KeyDB Sentinel还保证安全属性，即每个Sentinel都将使用不同的配置epoch故障转移同一master服务器。

## propagation配置

一旦Sentinel能够成功地对master服务器进行故障转移，它将开始广播新的配置，以便其他Sentinel更新关于给定master服务器的信息。

为了使故障转移被认为是成功的，它要求Sentinel能够向所选slave发送SLAVEOF NO ONE命令，
并且随后在master的信息输出中观察到切换到master。

此时，即使正在重新配置slave服务器，故障转移也被认为是成功的，并且所有Sentinel都需要开始报告新的配置。

新配置的传播方式是我们需要使用不同版本号（配置epoch）授权每个Sentinel故障转移的原因。

每个Sentinel使用KeyDB Pub/Sub消息在master服务器和所有slave中连续广播其master服务器配置版本。
同时，所有的Sentinel都在等待消息，看看其他Sentinel公布的配置是什么。

配置在"hello Pub/Sub"频道中广播。

因为每个配置都有不同的版本号，所以较大的版本总是胜过较小的版本。

例如，master mymaster的配置是slave所有Sentinel都相信master服务器在192.168.1.50:6379开始的。
此配置的版本为1。一段时间后，Sentinel被授权使用版本2进行故障转移。如果故障转移成功，它将开始广播新配置，
例如192.168.1.50:9000，版本2。所有其他实例都将看到此配置并相应地更新其配置，因为新配置具有更高版本。

这意味着Sentinel保证了第二个liveness属性：一组能够通信的Sentinel将聚合到具有更高版本号的相同配置。

基本上，如果对网络进行分区，每个分区都会收敛到更高的本地配置。在没有分区的特殊情况下，只有一个分区，
每个Sentinel都会同意配置。

## 分区下的一致性

KeyDB Sentinel配置最终是一致的，因此每个分区都会收敛到可用的更高配置。然而，在使用Sentinel的真实系统中，有三种不同的玩家：

* KeyDB实例。
* Sentinel实例。
* Client。

为了定义系统的行为，我们必须考虑这三个因素。

下面是一个简单的网络，其中有3个节点，每个节点运行一个KeyDB实例和一个Sentinel实例：

                +-------------+
                | Sentinel 1  |----- Client A
                | KeyDB 1 (M) |
                +-------------+
                        |
                        |
    +-------------+     |          +------------+
    | Sentinel 2  |-----+-- // ----| Sentinel 3 |----- Client B
    | KeyDB 2 (S) |                | KeyDB 3 (M)|
    +-------------+                +------------+

在这个系统中，最初的状态是KeyDB 3为主，KeyDB 1和KeyDB 2从。隔离旧master服务器时发生分区。Sentinels 1和2启动了故障转移，将Sentinel 1提升为新的master服务器。

Sentinel属性保证Sentinel 1和2现在拥有主服务器的新配置。不过，Sentinel 3仍然是旧的配置，因为它位于不同的分区中。

我们知道哨兵3会在网络分区恢复时更新其配置，但是如果有客户机与旧主机分区，分区期间会发生什么情况？

客户机仍然可以向旧主服务器KeyDB 3写入数据。当分区重新连接时，KeyDB 3将变成KeyDB 1的slave，分区期间写入的所有数据都将丢失。

根据您的配置，您可能希望或不希望发生以下情况：

* 如果您使用KeyDB作为缓存，那么客户端B仍然能够向旧主服务器写入数据（即使其数据将丢失）可能会很方便。
* 如果您使用KeyDB作为存储，这是不好的，您需要配置系统以部分防止此问题。

由于KeyDB是异步复制的，因此在这种情况下无法完全防止数据丢失，但是可以使用以下KeyDB配置选项绑定KeyDB 3和KeyDB 1之间的差异：

	min-slaves-to-write 1
	min-slaves-max-lag 10

使用上述配置（有关更多信息，请参阅KeyDB发行版中的self-commented redis.conf示例）KeyDB实例在充当master服务器时，如果不能写入至少一个从服务器，则将停止接受写入。由于复制是异步的，因此无法写入实际上意味着从机已断开连接，或者在超过指定的最大延迟秒数的情况下未向我们发送异步确认。

使用此配置，上述示例中的KeyDB 3在10秒后将不可用。分区修复后，Sentinel 3配置将收敛到新配置，客户端B将能够获取有效配置并继续。

一般来说，KeyDB+Sentinel作为一个整体是一个最终一致的系统，其中合并功能是最后一次故障转移，旧主服务器的数据被丢弃以复制当前主服务器的数据，因此总是有一个丢失已确认写入的窗口。这是由于KeyDB异步复制和系统的"虚拟"合并功能的丢弃特性。请注意，这并不是Sentinel本身的限制，如果使用强一致性复制状态机编排故障转移，则仍将应用相同的属性。只有两种方法可以避免丢失已确认的写入：

1.使用同步复制（以及正确的一致性算法来运行复制的状态机）。
2.使用最终一致的系统，其中可以合并同一对象的不同版本。

KeyDB目前无法使用上述任何系统，并且目前不在开发目标范围内。然而，有代理实现"2"的解决方案的顶部，比如SoundCloud Roshi, 或 Netflix Dynomite.

## Sentinel持续状态

Sentinel状态保存在Sentinel配置文件中。例如，每次收到或创建master服务器的新配置（leader Sentinels）时，
该配置将与配置epoch一起持久化在磁盘上。这意味着停止和重新启动Sentinel进程是安全的。

## TILT 倾斜模式

KeyDB Sentinel在很大程度上依赖于计算机时间：例如，为了了解实例是否可用，它会记住对PING命令最新成功应答的时间，并将其与当前时间进行比较，以了解它的使用时间。

但是，如果计算机时间以意外的方式改变，或者如果计算机很忙，或者进程由于某种原因被阻塞，Sentinel可能会以意外的方式开始工作。

倾斜模式是一种特殊的"保护"模式，当检测到可能降低系统可靠性的异常情况时，Sentinel可以进入该模式。
Sentinel计时器中断通常每秒调用10次，因此我们预计对计时器中断的两次调用之间的间隔大约为100毫秒。

Sentinel所做的是注册前一次定时器中断，并将其与当前呼叫进行比较：如果时差为负或出乎意料地大（2秒或更多），
则进入倾斜模式（或者如果它已经进入倾斜模式退出的延迟）。

当处于倾斜模式时，Sentinel将继续监视一切，但是：

	* 它完全停止了活动。
	* 它开始消极地回复SENTINEL is-master-down-by-addr请求，因为不再信任检测故障的能力。

如果在30秒钟内一切正常，则退出倾斜模式。

注意，在某种程度上，倾斜模式可以用许多内核提供的单调时钟API来代替。不过，目前尚不清楚这是否是一个好的解决方案，
因为当前系统在进程刚刚挂起或调度程序长时间不执行时会避免出现问题。

**警告：** 本文档是一个草案，随着Sentinel项目的发展，它所包含的指导方针可能会在未来发生变化。

# 支持KeyDB Sentinel的KeyDB客户端指南

KeyDB Sentinel是KeyDB实例的监视解决方案，用于处理KeyDB master服务器的自动故障转移和服务发现（谁是给定实例组的当前master服务器？）。
由于Sentinel既负责在故障转移期间重新配置实例，又负责向连接到KeyDB master服务器或slave服务器的客户端提供配置，
因此客户端需要对KeyDB Sentinel有明确的支持。

本文档针对的是KeyDB客户端开发人员，他们希望通过以下目标在客户端实现中支持Sentinel：

* 通过Sentinel自动配置客户端。
* 改进了KeyDB Sentinel自动故障转移的安全性。

有关KeyDB Sentinel如何工作的详细信息，请查看KeyDB文档，因为此文档仅包含KeyDB客户端开发人员所需的信息，而且读者应该熟悉KeyDB Sentinel的工作方式。

# 通过Sentinel发现KeyDB服务

KeyDB Sentinel用"stats"或"cache"之类的名称标识每个master节点。每个名称实际上标识了一组实例，由一个master实例和一个可变数量的slave实例组成。

在发生诸如自动故障转移、手动触发的故障转移（例如为了升级KeyDB实例）和其他原因等事件后，用于网络中特定用途的KeyDB主机的地址可能会更改。

通常KeyDB client具有某种硬编码配置，将网络中KeyDB主实例的地址指定为IP地址和端口号。但是，如果master地址更改，则需要对每个client进行手动干预。

支持Sentinel的KeyDB客户端可以使用KeyDB Sentinel从主机名中自动发现KeyDB主机的地址。因此，支持Sentinel的客户机应该可以选择接受以下输入，而不是硬编码的IP地址和端口：

* 指向已知Sentinel实例的ip:port对列表。
* 服务的名称，如"stats" 或 "cache"。

这是一个client应该遵循的过程，以便从Sentinel列表和服务名开始获取master地址。

## 连接第一个Sentinel

client应该迭代Sentinel地址列表。对于每个地址，它都应该尝试使用一个短超时（几百毫秒的顺序）连接到Sentinel。出现错误或超时时，应尝试下一个Sentinel地址。

如果尝试所有的Sentinel地址都没有成功，则应向client返回一个错误。

对client请求的第一个Sentinel响应应该放在列表的开头，这样在下次重新连接时，我们将首先尝试在上一次连接尝试中可以访问的Sentinel，从而将延迟最小化。

## 询问master地址

与Sentinel建立连接后，客户端应重试在Sentinel上执行以下命令：

    SENTINEL get-master-addr-by-name master-name

其中主名称应替换为用户指定的实际服务名称。

此调用的结果可以是以下两个答复之一：

* ip:port对。
* 无效的答复。这意味着Sentinel不认识这位master。

如果接收到ip:port对，则应使用此地址连接到KeyDB master。否则，如果收到空应答，client应尝试列表中的下一个Sentinel。

## 在目标实例中调用ROLE命令

一旦client发现master实例的地址，它应该尝试与master实例建立连接，并调用ROLE命令以验证实例的角色实际上是master实例。

如果ROLE命令不可用（它是KeyDB 2.8.12中引入的），client可以使用INFO replication命令解析输出的ROLE: 字段。

如果实例不是预期的master实例，则client应等待一小段时间（几百毫秒），然后从步骤1开始重试。

# 处理重新连接

一旦将服务名称解析为master地址并与KeyDBmaster实例建立连接，每次需要重新连接时，client应使用从步骤1重新启动的Sentinels重新解析地址。
例如，Sentinel应再次联系以下情况：

* 如果客户端在超时或套接字错误后重新连接。
* 如果客户端由于显式关闭或用户重新连接而重新连接。

在上述情况以及client与KeyDB服务器失去连接的任何其他情况下，client应再次解析master地址。

# Sentinel故障转移断开连接

从KeyDB 2.8.12开始，当KeyDB Sentinel更改实例的配置时，例如将slave实例升级为master实例、将master实例降级以在故障转移后复制到新的master实例，
或只是更改过时slave实例的master地址，它向实例发送一个CLIENT KILL type normal命令，以确保所有客户端都与重新配置的实例断开连接。这将迫使client再次解析master地址。
 
如果client将使用尚未更新的信息与Sentinel联系，则通过 ROLE 命令对KeyDB实例角色的验证将失败，从而使client能够检测到所联系的Sentinel提供了过时的信息，并将重试。

注意：过时的master可能在客户端联系过时的Sentinel实例的同时返回联机状态，因此client可能连接到过时的master，但角色输出将匹配。
不过，当master服务器再次返回时，Sentinel将尝试将其降级为slave服务器，slave而触发新的断开连接。同样的道理也适用于连接到过时的slave，这些slave将被重新配置为使用不同的master进行复制。

# 连接到slave服务器

有时client对连接到slave感兴趣，例如为了扩展读取请求。此协议通过稍微修改步骤2来支持连接到slave。而不是调用以下命令：

    SENTINEL get-master-addr-by-name master-name

客户应该改为调用：

    SENTINEL slaves master-name

以便检索slave实例的列表。

对称地, client应该使用ROLE命令验证实例实际上是一个slave，以避免使用master扩展读取查询。

# 连接池
 
 对于实现连接池的客户端，在重新连接单个连接时，应该再次联系Sentinel，并且在master地址改变的情况下，
 所有现有连接都应该关闭并连接到新地址。
 
# 错误报告
 
如果出现错误，client应该正确地将信息返回给用户。明确地：

* 如果无法联系到Sentinel（这样客户端就永远无法通过名称获得Sentinel get-master-addr-by-name的回复），
则应返回一个错误，该错误清楚地表明KeyDB Sentinel是不可访问的。
* 如果池中的所有Sentinels都以空回复进行回复，则应通知用户一个错误，即Sentinels不知道此主机名。

# Sentinel列表自动刷新

（可选）在收到get-master-addr-by-name的成功答复后，client可以按照以下过程更新其Sentinel节点的内部列表：

使用SENTINEL Sentinels<master name>命令获取此主机的其他Sentinel列表。

添加每个IP：端口对在列表的末尾已经不存在了。

client不需要使列表能够持久地更新其自己的配置。升级Sentinel列表的内存表示的能力对于提高可靠性已经很有用。

# 订阅Sentinel事件以提高响应能力

Sentinel文档显示了客户机如何使用Pub/Sub连接到Sentinel实例，以便订阅KeyDB实例配置中的更改。

此机制可用于加速客户机的重新配置，即客户机可以监听Pub/Sub以了解何时发生配置更改，
以便运行本文档中解释的三步协议以解析新的KeyDB 主（或从）地址。

但是，通过Pub/Sub接收的更新消息不应替代上述过程，因为不能保证客户端能够接收所有更新消息。
