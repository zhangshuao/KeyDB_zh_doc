# 集群规范

欢迎使用**KeyDB集群规范**。在这里您将找到有关KeyDB集群的算法和设计原理的信息。
本文档是一个正在进行的工作，因为它与KeyDB的实际实现是连续同步的。

## 设计的主要性质和原理

### KeyDB集群目标

KeyDB集群是KeyDB的一个分布式实现，其目标如下，在设计中按重要性排序：

* 高性能和线性可扩展性高达1000个节点。没有代理，异步复制被使用，并且没有对值执行合并操作。
* 可接受的写安全程度：系统尝试（以最大努力的方式）保留来自与大多数主节点连接的客户端的所有写操作。通常有一些小窗口，可以在其中丢失已确认的写入。
  当客户端位于少数分区时，丢失已确认写入的窗口会更大。
* 可用性：KeyDB集群能够在大多数主节点都可访问的分区中生存，并且对于每个不再可访问的主节点，至少有一个可访问的从节点。
  此外，使用副本迁移，不再由任何从机复制的主机将从一个由多个从机覆盖的主机接收一个副本。

本文档中描述的内容在KeyDB 3.0或更高版本中实现。

### 实现的子集

KeyDB集群实现KeyDB的非分布式版本中可用的所有单键命令。只要键都属于同一个节点，就可以实现执行复杂多键操作（如集合类型联合或交集）的命令。

KeyDB Cluster实现了一个名为**hash tags**的概念，该概念可用于强制将某些key存储在同一节点中。
但是，在手动重新硬装期间，多键操作可能会在一段时间内不可用，而单键操作始终可用。

KeyDB集群不支持多个数据库，如KeyDB的独立版本。只有数据库0，不允许使用SELECT命令。

## KeyDB集群协议中的客户机和服务器角色

在KeyDB中，集群节点负责保存数据，并获取集群的状态，包括将key映射到正确的节点。群集节点还可以自动发现其他节点，检测不工作的节点，
并在需要时将从属节点提升为主节点，以便在发生故障时继续运行。

为了执行它们的任务，所有的集群节点都使用一个TCP总线和一个称为KeyDB集群总线的二进制协议进行连接。
每个节点都使用集群总线连接到集群中的每个其他节点。节点使用gossip协议来传播关于集群的信息，以便发现新的节点，发送ping数据包以确保所有其他节点正常工作，
并发送集群消息以指示特定条件。集群总线还用于在集群中传播Pub/Sub消息，并在用户请求时安排手动故障切换（手动故障切换是指不由KeyDB集群故障检测器启动，而是由系统管理员直接启动的故障切换）。

由于群集节点无法代理请求，因此可以使用重定向错误-MOVED和-ASK将客户端重定向到其他节点。
理论上，客户机可以向集群中的所有节点发送请求，如果需要，可以重定向，因此客户机不需要保持集群的状态。
但是，能够缓存键和节点之间的映射的客户端可以以合理的方式提高性能。

## 写安全

KeyDB集群在节点之间使用异步复制，最后一次故障转移赢得隐式合并函数。这意味着最后选择的主数据集最终将替换所有其他副本。在分区期间，总是有一个可能丢失写操作的时间窗口。
但是，对于连接到大多数主服务器的客户端和连接到少数主服务器的客户端，这些窗口是非常不同的。

KeyDB Cluster与在少数方执行的写操作相比，更努力地保留由连接到大多数主服务器的客户端执行的写操作。
以下是导致大多数分区在故障期间接收到的已确认写入丢失的场景示例：

1.写入可以到达master，但是虽然主节点可以回复客户机，但是写入不能通过主节点和从节点之间使用的异步复制传播到从节点。
如果master死了，而写的东西没有送到奴隶手上，那么如果master在足够长的时间内无法到达，以致其中一个奴隶被提升，那么写的东西就会永远丢失。
在master节点完全突然失败的情况下，通常很难观察到这一点，因为主节点试图同时回复客户机（确认写入）和从节点（传播写入）。
然而，这是一个现实世界的失败模式。

2.另一种理论上可能出现的写操作丢失的故障模式如下：

* 由于分区，无法访问主控形状。
* 它被它的一个奴隶给毁了。
* 一段时间后，它可能会再次到达。
* 具有过时路由表的客户端可以在由群集将旧主服务器转换为从服务器（新主服务器）之前写入旧主服务器。

第二种故障模式不太可能发生，因为主节点无法与大多数其他主节点通信足够长的时间以进行故障转移，将不再接受写入，并且当分区固定时，仍会在很短的时间内拒绝写入，
以允许其他节点通知配置更改。此故障模式还要求尚未更新客户端的路由表。

以分区少数方为目标的写操作有一个更大的窗口，可以在其中丢失。例如，KeyDB Cluster在有少数主服务器和至少一个或多个客户机的分区上丢失了非常多的写操作，
因为如果主服务器在多数端发生故障，发送给主服务器的所有写操作都可能丢失。

具体地说，对于要进行故障转移的主服务器，大多数主服务器至少在节点超时时无法访问它，因此，如果在该时间之前修复了分区，则不会丢失任何写操作。
当分区持续超过NODE_TIMEOUT时，在该点之前在少数方执行的所有写操作都可能丢失。然而，KEYDB集群的少数方将在拒绝NoDeTimeOut时间的情况下开始拒绝写入，
因此有一个最大窗口，此后少数窗口将不再可用。因此，在这段时间之后，不会接受或丢失任何写入。

## 可用性

KeyDB集群在分区的少数方不可用。在分区的多数区中，假设每个不可访问的主服务器至少有大多数主服务器和一个从服务器，则在节点超时时间加上从服务器选择并故障转移其主服务器所需的几秒钟后，
群集再次可用（故障转移通常在1或2秒钟内执行）。

这意味着KeyDB集群的设计是为了在集群中的几个节点出现故障时生存下来，但对于在出现较大的网络拆分时需要可用性的应用程序来说，它不是一个合适的解决方案。

在一个由N个主节点组成的集群的例子中，每个节点都有一个从节点，只要一个节点被分割开，集群的大多数端就仍然可用，
当两个节点被分开时（在第一个节点失败后，我们总共剩下了N*2-1个节点，而没有副本的唯一主节点失败的概率是1/（N*2-1））仍然可用。

例如，在一个每个节点有5个节点和一个从节点的集群中，有1/（5*2-1）=11.11%的概率在两个节点被从大多数节点分区后，集群将不再可用。

由于KeyDB集群的一个称为副本迁移的特性，集群的可用性在许多实际场景中得到了改善，因为副本迁移到孤立的主节点（主节点不再有副本）。
因此，在每次成功的失败事件中，集群都可以重新配置从属布局，以便更好地抵抗下一次失败。

## 性能

在KeyDB集群中，节点不会将命令代理到负责给定key的右节点，而是将客户机重定向到服务于给定key空间一部分的右节点。

最终，客户机获得集群的最新表示以及哪个节点为哪些key子集提供服务，因此在正常操作期间，客户机直接联系正确的节点以发送给定的命令。

由于使用异步复制，节点不会等待其他节点的写入确认（如果未使用wait命令显式请求）。

此外，由于多键命令仅限于近键，因此数据在节点之间永远不会移动，除非重新硬装。

正常操作的处理方式与单个KeyDB实例完全相同。这意味着，在具有N个主节点的KeyDB集群中，您可以期望与单个KeyDB实例乘以N的性能相同，
因为设计是线性扩展的。同时，查询通常在一次往返中执行，因为客户端通常保留与节点的持久连接，因此延迟数字也与单个独立KeyDB节点的情况相同。

KeyDB集群的主要目标是在保持弱而合理的数据安全性和可用性的同时，具有很高的性能和可扩展性。

## 为什么避免合并操作

KeyDB集群设计避免了多个节点中相同键值对的冲突版本，就像KeyDB数据模型的情况一样，这并不总是可取的。
KeyDB中的值通常非常大；通常会看到包含数百万个元素的列表或排序集。数据类型在语义上也很复杂。传输和合并这些类型的值可能是一个主要的瓶颈，并且/或者可能需要应用程序端逻辑的非平凡参与、存储元数据的额外内存等等。

这里没有严格的技术限制。CRDTs或同步复制的状态机可以为类似KeyDB的复杂数据类型建模。但是，这样的系统的实际运行时行为与KeyDB集群并不相似。
KeyDB集群的设计是为了覆盖非集群KeyDB版本的确切用例。

# KeyDB集群主要组件概述

## key分配模型

key空间被划分为16384个slot，有效地设置了16384个主节点的集群大小上限（但是建议的最大节点大小是1000个节点）。

集群中的每个主节点都处理16384哈希槽的一个子集。当没有正在进行的群集重新配置（即哈希槽从一个节点移动到另一个节点）时，群集是稳定的。
当集群稳定时，单个散列槽将由单个节点提供服务（但是，服务节点可以有一个或多个从机，在网络拆分或故障时将替换它，并且可以使用这些从机来扩展读取操作，其中读取陈旧数据是可接受的）。

用于将key映射到哈希槽的基本算法如下（请阅读下一段，了解此规则的哈希标记异常）：

    HASH_SLOT = CRC16(key) mod 16384

CRC16规定如下：

* Name：XMODEM（也称为ZMODEM或CRC-16/ACORN）
* Width：16位
* Poly:1021（实际上是x^16+x^12+x^5+1）
* Initialization：0000
* Reflect Input反射输出 byte：False
* Reflect Output反射输出 CRC:False
* Xor constant to output CRC:0000的异或常数
* "123456789"的输出：31C3

使用了16个CRC16输出位中的14个（这就是上面公式中有16384模运算的原因）。

在我们的测试中，CRC16在16384插槽上均匀分布不同类型的key方面表现得非常好。

**注：**所用CRC16算法的参考实现见本文件附录A。

## key哈希标记

计算用于实现哈希标记的哈希槽时出现异常。哈希标记是一种确保在同一哈希槽中分配多个key的方法。
用于在KeyDB集群中实现多key操作。

为了实现哈希标记，在某些条件下，key的哈希槽的计算方式略有不同。
如果密钥包含"{…}"模式，则只对{和}之间的子字符串进行哈希处理，以获取哈希槽。
但是，由于{或}可能多次出现，因此该算法由以下规则很好地指定：

* 如果key包含{字符。
* 如果右边有一个}字符{
* 如果{的第一次出现和}的第一次出现之间有一个或多个字符。

然后不散列键，只散列出{第一次出现与}第二次出现之间的内容。

示例：

    * 两个键{user1000}.following和{user1000}.followers将散列到同一个散列槽，因为只有子字符串user1000将被散列以计算散列槽。
    
    * 对于key Fo{{}{Bar }，整个key通常会被哈希，因为第一次出现{右边是}，中间没有字符。
    
    * 对于key foo{bar}zap，子字符串{bar将被散列，因为它是{的第一个匹配项与其右侧}的第一个匹配项之间的子字符串。
    
    * 对于key foo{bar}{zap}，子字符串条将被散列，因为算法在{和}的第一个有效或无效（内部没有字节）匹配处停止。
    
    * 该算法的结果是，如果key以{}开头，则保证将其作为一个整体进行散列。这在使用二进制数据作为key名时非常有用。

添加hash标记异常，下面是用Ruby和C语言实现的hash_SLOT函数。

Ruby 示例代码：

    def HASH_SLOT(key)
        s = key.index "{"
        if s
            e = key.index "}",s+1
            if e && e != s+1
                key = key[s+1..e-1]
            end
        end
        crc16(key) % 16384
    end

C 示例代码：

    unsigned int HASH_SLOT(char *key, int keylen) {
        int s, e; /* start-end indexes of { and } */
    
        /* Search the first occurrence of '{'. */
        for (s = 0; s < keylen; s++)
            if (key[s] == '{') break;
    
        /* No '{' ? Hash the whole key. This is the base case. */
        if (s == keylen) return crc16(key,keylen) & 16383;
    
        /* '{' found? Check if we have the corresponding '}'. */
        for (e = s+1; e < keylen; e++)
            if (key[e] == '}') break;
    
        /* No '}' or nothing between {} ? Hash the whole key. */
        if (e == keylen || e == s+1) return crc16(key,keylen) & 16383;
    
        /* If we are here there is both a { and a } on its right. Hash
         * what is in the middle between { and }. */
        return crc16(key+s+1,e-s-1) & 16383;
    }

## 群集节点属性

群集中的每个节点都有一个唯一的名称。节点名是160位随机数的十六进制表示，在第一次启动节点时获得（通常使用/dev/urandom）。
节点将在节点配置文件中保存其ID，并将永远使用相同的ID，或者至少只要系统管理员未删除节点配置文件，或者通过CLUSTER reset命令请求硬重置。

节点ID用于标识整个集群中的每个节点。给定节点可以更改其IP地址，而无需同时更改节点ID。
群集还可以检测IP/端口中的更改，并使用运行在群集总线上的gossip协议重新配置。

节点ID不是与每个节点关联的唯一信息，而是唯一始终全局一致的信息。每个节点还具有以下关联的信息集。
一些信息是关于这个特定节点的集群配置细节的，并且最终在集群中是一致的。其他一些信息，比如上次ping节点时，是每个节点的本地信息。

每个节点都维护集群中已知的其他节点的以下信息：节点ID、IP和端口、一组标志、如果标记为从属节点，则该节点的主节点是什么、上一次对该节点进行ping和上一次接收到pong，
节点的当前配置纪元（在本规范后面解释）、链路状态以及最终服务的散列槽集。

集群节点文档中描述了所有节点字段的详细说明。

CLUSTER NODES命令可以发送到集群中的任何节点，并根据查询到的集群节点的本地视图提供集群的状态和每个节点的信息。

下面是发送到由三个节点组成的小集群中的主节点的CLUSTER NODES命令的示例输出。

    $ keydb-cli cluster nodes
    d1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364
    3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729
    d289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095

在上面的列表中，不同的字段按顺序排列：node id、address:port、flags、last ping sent、last pong received、configuration epoch、link state、slots。
一旦我们谈到KeyDB集群的特定部分，就会涉及到上述字段的详细信息。

## 集群总线

每个KeyDB集群节点都有一个额外的TCP端口，用于接收来自其他KeyDB集群节点的传入连接。
此端口与用于接收来自客户端的传入连接的普通TCP端口有固定的偏移量。要获得KeyDB集群端口，应该在普通命令端口上添加10000。
例如，如果KeyDB节点正在端口6379上侦听客户端连接，那么集群总线端口16379也将打开。

节点到节点的通信仅使用集群总线和集群总线协议：由不同类型和大小的帧组成的二进制协议。
集群总线二进制协议没有公开的文档，因为它不适合外部软件设备使用此协议与KeyDB集群节点进行对话。
但是，通过读取KeyDB集群源代码中的Cluster.h和Cluster.c文件，可以获得有关集群总线协议的更多详细信息。

## 群集拓扑

KeyDB集群是一个完整的网格，其中每个节点使用TCP连接与其他每个节点连接。

在由N个节点组成的集群中，每个节点都有N-1个传出TCP连接和N-1个传入连接。

这些TCP连接始终保持活动状态，并且不是按需创建的。当一个节点需要响应集群总线中的ping的pong应答时，在等待足够长的时间将该节点标记为不可访问之前，
它将尝试通过从头重新连接来刷新与该节点的连接。

当KeyDB集群节点形成一个完整的网格时，**节点使用gossip协议和配置更新机制，以避免在正常情况下节点之间交换过多的消息**，因此交换的消息数不是指数的。

## 节点握手

节点总是接受群集总线端口上的连接，甚至在收到ping时回复ping，即使ping节点不受信任。
但是，如果发送节点不被视为集群的一部分，则接收节点将丢弃所有其他数据包。

一个节点只能通过两种方式接受另一个节点作为集群的一部分

    * 如果一个节点出现了一个MEET消息。meet消息与PING消息完全相似，但会强制接收方接受节点作为集群的一部分。
    只有当系统管理员通过以下命令请求时，节点才会向其他节点发送会议消息：
    
    CLUSTER MEET ip port
    
    * 如果已受信任的节点将gossip另一个节点，则该节点还将注册另一个节点作为群集的一部分。
    所以如果A知道B，B知道C，最终B会向A发送关于C的流言蜚语消息。当这种情况发生时，A会将C注册为网络的一部分，并尝试与C连接。

这意味着只要我们在任何连通图中连接节点，它们最终将自动形成一个完全连通图。
这意味着集群能够自动发现其他节点，但前提是存在由系统管理员强制的受信任关系。

这种机制使得集群更健壮，但防止不同的key数据库集群在IP地址或其他网络相关事件的更改后意外混合。

# 重定向和重新分片resharding

## 移动重定向

KeyDB客户机可以向集群中的每个节点（包括从节点）发送查询。节点将分析查询，如果它是可接受的（即，查询中只提到一个键，或者提到的多个键都属于同一个哈希槽），
它将查找哪个节点负责该键所属的哈希槽。

如果哈希槽由节点提供服务，则只需简单地处理查询，否则节点将检查其内部哈希槽到节点的映射，
并使用移动错误回复客户端，如下例所示：

    GET x
    -MOVED 3999 127.0.0.1:6381

错误包括key（3999）的哈希槽和可以服务查询的实例的ip:端口。客户端需要将查询重新发出到指定节点的IP地址和端口。
请注意，即使客户端在重新发出查询之前等待很长时间，并且在群集配置更改的同时，如果哈希槽3999现在由另一个节点提供服务，则目标节点将再次以移动错误进行回复。
如果联系的节点没有更新的信息，也会发生同样的情况。

因此，虽然从IDs识别集群节点的角度来看，我们试图简化与客户机的接口，只是在hash插槽和由IP:port对识别的KeyDB节点之间公开一个映射。

客户端不需要这样做，但应该尝试记住哈希槽3999由127.0.0.1:6381提供服务。这样，一旦需要发出一个新命令，它就可以计算目标key的哈希槽，并有更大的机会选择正确的节点。

另一种方法是在接收到移动的重定向时使用cluster NODES或cluster SLOTS命令刷新整个客户端集群布局。
当遇到重定向时，可能重新配置了多个插槽，而不是一个，因此尽快更新客户端配置通常是最佳策略。

注意，当集群是稳定的（配置中没有正在发生的变化）时，最终所有的客户端将获得散列槽->节点的映射，使得集群有效，客户端直接在没有重定向、
代理或其他单点故障实体的情况下对正确的节点进行寻址。

客户机**还必须能够处理本文档后面描述的-ASK重定向**，否则它不是一个完整的KeyDB集群客户机。

## 群集实时重新配置

KeyDB Cluster支持在集群运行时添加和删除节点的功能。添加或删除节点被抽象为相同的操作：将哈希槽从一个节点移动到另一个节点。
这意味着可以使用相同的基本机制来重新平衡集群、添加或删除节点等。

* 要向集群添加新节点，将向集群中添加一个空节点，并将一些散列槽组从现有节点移到新节点。
* 要从集群中删除节点，分配给该节点的散列时隙被移动到其他现有节点。
* 为了重新平衡集群，在节点之间移动一组给定的哈希槽。

实现的核心是能够移动散列槽。从实际的角度来看，散列槽只是一组键，因此KeyDB集群在重新硬装期间真正做的是将键从一个实例移动到另一个实例。
移动哈希槽意味着将所有发生哈希的key移动到此哈希槽中。

为了理解这是如何工作的，我们需要显示用于操作KeyDB集群节点中的slots转换表的CLUSTER子命令。

可以使用以下子命令（在这种情况下，这些子命令不起作用）

    * CLUSTER ADDSLOTS slot1 [slot2] ... [slotN]
    * CLUSTER DELSLOTS slot1 [slot2] ... [slotN]
    * CLUSTER SETSLOT slot NODE node
    * CLUSTER SETSLOT slot MIGRATING node
    * CLUSTER SETSLOT slot IMPORTING node

前两个命令ADDSLOTS和DELSLOTS只用于将插槽分配（或移除）给KeyDB节点。
分配时隙意味着告诉给定的主节点它将负责存储和服务指定哈希时隙的内容。

分配散列槽后，它们将使用gossip协议在集群中传播，稍后在配置传播部分中指定。

ADDSLOTS命令通常在从头创建新集群时使用，以便为每个主节点分配所有16384个可用哈希槽的子集。

DELSLOTS主要用于手动修改集群配置或调试任务：实际上很少使用。

如果使用SETSLOT <slot> 节点形式，则SETSLOT子命令用于将插槽分配给特定的节点ID。
否则，可以在迁移和导入两种特殊状态下设置插槽。这两种特殊状态用于将哈希槽从一个节点迁移到另一个节点。


* 当时隙设置为迁移时，节点将接受关于该散列时隙的所有查询，但仅当存在所存在的key时，
  否则使用向ASK请求重定向到迁移目标的节点来转发查询。
* 当插槽设置为导入时，节点将接受有关此哈希插槽的所有查询，但前提是请求前面有一个ASKING命令。
  如果客户端没有发出ASKING命令，则查询将通过一个移动的重定向错误重定向到真正的哈希槽所有者，这是正常情况。

让我们通过一个散列槽迁移的例子来更清楚地说明这一点。假设我们有两个KeyDB主节点，称为A和B。
我们希望将哈希槽8从A移动到B，因此我们发出如下命令：

* We send B: CLUSTER SETSLOT 8 IMPORTING A
* We send A: CLUSTER SETSLOT 8 MIGRATING B

所有其他节点在每次使用属于散列槽8的key查询客户机时都会继续将它们指向节点"A""，因此会发生以下情况：

* 所有有关现有key的查询都由"A"处理。
* 所有关于A中不存在键的查询都由"B"处理，因为"A"会将客户端重定向到"B""。

这样我们就不再在"A"中创建新的键。同时，在RESHARDIN和KEYDB集群配置期间使用的一个特殊程序keydb-trib 将将哈希槽8中的现有key从A迁移到B，这是使用以下命令执行的：

    CLUSTER GETKEYSINSLOT slot count

上面的命令将返回指定哈希槽中的count键。对于返回的每个key，keydb-trib发送节点"A"一个MIGRATE命令，该命令将以原子方式将指定的key从A迁移到B（两个实例都锁定了迁移key所需的时间（通常很短），因此不存在争用条件）。
这就是迁移的工作原理：

    MIGRATE target_host target_port key target_database id timeout

MIGRATE将连接到目标实例，发送key的序列化版本，并且在收到OK代码后，将从其自己的数据集中删除旧key。
从外部客户端的角度来看，在任何给定的时间内A或B都存在key。

在KeyDB集群中，不需要指定0以外的数据库，但MIGRATE是一个通用命令，可用于不涉及KeyDB集群的其他任务。
即使在移动复杂键（如长列表）时，迁移也被优化为尽可能快，但在KeyDB集群中，如果使用数据库的应用程序中存在延迟限制，
则重新配置存在大键的集群不被视为明智的过程。

当迁移过程最终完成时，SETSLOT <slot> NODE <node-id> 命令被发送到迁移涉及的两个节点，以便再次将插槽设置为其正常状态。
相同的命令通常发送到所有其他节点，以避免等待新配置在集群中自然传播。

## 请求重定向

在上一节中，我们简要地讨论了ASK重定向。为什么我们不能简单地使用移动重定向？因为虽然MOVED意味着我们认为散列槽是由另一个节点永久服务的，
下一个查询应该针对指定节点进行尝试，ASK意味着只向指定节点发送下一个查询。

这是必需的，因为下一个关于hash slot 8的查询可能是关于仍然在a中的密钥，所以我们总是希望客户端在需要时尝试a和B。
由于这只发生在16384个可用哈希槽中的一个，因此集群上的性能影响是可以接受的。

我们需要强制客户机的行为，以便确保客户机仅在尝试A之后才尝试节点B，如果客户机在发送查询之前发送ASKING命令，
则节点B将只接受设置为导入的插槽的查询。

基本上，ASKING命令在客户机上设置一个一次性标志，强制节点提供有关导入时隙的查询。

从客户端的角度来看，ASK重定向的完整语义如下：

* 如果接收到ASK重定向，则仅发送重定向到指定节点的查询，但继续将后续查询发送到旧节点。
* 使用ASKING命令启动重定向查询。
* 尚未更新本地客户端表以将哈希槽8映射到B。

哈希槽8迁移完成后，A将发送移动的消息，客户端可以将哈希槽8永久映射到新的IP和端口对。
注意，如果有错误的客户机在前面执行映射，这不是问题，因为它在发出查询之前不会发送ASKING命令，
因此B将使用移动重定向错误将客户机重定向到。

在CLUSTER SETSLOT命令文档中，用类似的术语解释了插槽迁移，但使用了不同的措辞（为了文档中的冗余）。

## 客户端优先连接和重定向处理

虽然KeyDB集群客户机实现可能不记得内存中的插槽配置（插槽号和为其提供服务的节点地址之间的映射），并且只能通过联系等待重定向的随机节点来工作，
但这样的客户机将非常低效。

KeyDB集群客户机应该尽量智能到能够记住插槽配置。但是，此配置不要求是最新的。因为联系错误的节点只会导致重定向，
这应该会触发客户端视图的更新。

在两种不同的情况下，客户端通常需要获取插槽和映射节点地址的完整列表：

* 在启动时以填充初始插槽配置。
* 当收到MOVED重定向时。

注意，客户机可以通过只更新其表中的移动插槽来处理移动重定向，但是这通常不是有效的，因为通常一次修改多个插槽的配置（例如，如果从服务器升级为主服务器，则旧主服务器提供的所有插槽都将重新映射）。
通过从头获取插槽到节点的完整映射，对移动的重定向做出反应要简单得多。

为了检索插槽配置，KeyDB Cluster提供了Cluster NODES命令的替代方法，该命令不需要解析，只向客户机提供严格需要的信息。

新命令称为CLUSTER SLOTS，它提供一个插槽范围数组，以及为指定范围服务的相关主节点和从节点。

以下是CLUSTER SLOTS的输出示例：

    127.0.0.1:7000> cluster slots
    1) 1) (integer) 5461
       2) (integer) 10922
       3) 1) "127.0.0.1"
          2) (integer) 7001
       4) 1) "127.0.0.1"
          2) (integer) 7004
    2) 1) (integer) 0
       2) (integer) 5460
       3) 1) "127.0.0.1"
          2) (integer) 7000
       4) 1) "127.0.0.1"
          2) (integer) 7003
    3) 1) (integer) 10923
       2) (integer) 16383
       3) 1) "127.0.0.1"
          2) (integer) 7002
       4) 1) "127.0.0.1"
          2) (integer) 7005
          
返回数组的每个元素的前两个子元素是范围的 开始-结束 槽。其他元素表示地址端口对。第一个地址端口对是为插槽提供服务的主端口，
而附加的地址端口对是为同一插槽提供服务的所有从属端口，它们不处于错误状态（即未设置失败标志）。

例如，输出的第一个元素表示，从5461到10922（包括开始和结束）的插槽由127.0.0.1:7001提供服务，并且可以在127.0.0.1:7004处缩放与从机接触的只读负载。

如果群集配置错误，群集插槽不保证返回覆盖整个16384插槽的范围，因此客户端应初始化插槽配置映射，用空对象填充目标节点，
如果用户尝试执行有关属于未分配插槽的ke的命令，则报告y误。

在发现插槽未分配时向调用方返回错误之前，客户端应再次尝试获取插槽配置，以检查群集现在是否配置正确。
      
## 多keys操作

使用 hash tags，客户端可以自由使用多key操作。例如，以下操作有效：

    MSET {user:1000}.name Angela {user:1000}.surname White

当key所属的哈希槽的重新硬装正在进行时，多key操作可能变得不可用。

更具体地说，即使在重定位过程中，仍然存在着所有存在于相同节点（源或目的节点）的键的多键操作。

对不存在的key或在源节点和目的节点之间的重新划分时的操作将生成一个-TRYAGAIN错误。
客户端可以在一段时间后尝试该操作，或报告错误。

一旦指定散列槽的迁移终止，所有多键操作就可以再次用于该散列槽。

## 使用从节点扩展读取

通常，从节点会将客户机重定向到给定命令中所涉及哈希槽的权威主机，但是客户机可以使用从节点来使用READONLY命令缩放读取。

READONLY告诉KeyDB集群从节点，客户端可以读取可能过时的数据，并且对运行写查询不感兴趣。

当连接处于只读模式时，只有当操作涉及到从属主节点未提供服务的密钥时，群集才会向客户端发送重定向。这可能是因为：

    1.客户机发送了一个关于这个从机的主机从未服务过的散列槽的命令。
    2.群集已重新配置（例如resharded），从服务器无法再为给定的哈希槽提供命令。
    
当这种情况发生时，客户机应该更新hashslot映射，如前几节所述。
可以使用READWRITE命令清除连接的只读状态。

# 容错性

## 心跳和gossip信息

KeyDB集群节点不断交换ping和pong数据包。这两种包具有相同的结构，并且都携带重要的配置信息。
唯一实际的区别是消息类型字段。我们将把乒乓球和乒乓球的数据包的总和称为心跳数据包。

通常，节点发送ping数据包，触发接收器用pong数据包应答。然而，这不一定是真的。节点可以只发送pong包，向其他节点发送关于其配置的信息，而不触发应答。这很有用，例如，为了尽快广播新配置。

通常，一个节点每秒会ping几个随机节点，这样，每个节点发送（和接收到的pong数据包）的总数都是一个常量，而与集群中的节点数无关。

如果将NODE_TIMEOUT设置为一个小数字，并且节点数（N）非常大，则全局交换的消息数可以是相当大的，
因为每个节点都会尝试每隔一半的NODE_TIMEOUT时间ping其他没有新信息的节点。

例如，在节点超时设置为60秒的100节点集群中，每个节点将尝试每30秒发送99个ping，总ping数为每秒3.3个。
乘以100个节点，这在整个集群中是每秒330个ping。

有一些方法可以降低消息的数量，但是KeyDB集群故障检测当前使用的带宽没有报告问题，因此目前使用的是明显的直接设计。
注意，即使在上面的例子中，每秒交换的330个包在100个不同的节点中被均匀地分配，因此每个节点接收的业务是可接受的。

## 心跳包内容

ping和pong包包含一个对所有类型的包都通用的头（例如请求故障转移投票的包），以及一个特定于ping和pong包的特殊Gossip部分。

公共头包含以下信息：

    * Node ID，一个160位的伪随机字符串，在第一次创建节点时分配，并且在KeyDB集群节点的整个生命周期内保持不变。
    * 发送节点的currentEpoch和configEpoch字段，用于装载KeyDB集群使用的分布式算法（这将在下一节中详细说明）。如果节点是从节点，则configEpoch是其主节点的最后一个已知configEpoch。
    * 节点标志，指示该节点是否是从节点、主节点和其他单位节点信息。
    * 发送节点提供的哈希槽的位图，如果该节点是从节点，则为其主节点提供的槽的位图。
    * 发送方TCP基本端口（即KeyDB用于接受客户端命令的端口；向该端口添加10000可获得群集总线端口）。
    * 从发送方的角度看集群的状态（关闭或确定）。
    * 发送节点的主节点ID（如果它是从节点）。

ping和pong也包含gossip部分。本节向接收方提供发送方节点对集群中其他节点的看法。
gossip部分只包含发送方已知的节点集中一些随机节点的信息。gossip部分中提到的节点数与集群大小成正比。

对于添加到gossip部分中的每个节点，将报告以下字段：

* 节点ID。
* 节点的IP和端口。
* 节点标志。

gossip部分允许接收节点从发送方的角度获取有关其他节点状态的信息。这对于故障检测和发现集群中的其他节点都很有用。

## 故障检测

KeyDB集群故障检测用于识别大多数节点不再能够访问主节点或从节点，然后通过将从节点提升到主节点的角色来响应。
当无法进行从机升级时，集群将处于错误状态，以停止从客户端接收查询。

如前所述，每个节点都接受与其他已知节点关联的标志列表。有两个用于故障检测的标志称为PFAIL和FAIL。
PFAIL表示可能的故障，是一种未确认的故障类型。失败意味着一个节点正在失败，并且大多数主节点在固定的时间内都确认了这种情况。

#### PFAIL flag:

当节点超过节点超时时间无法访问时，节点用PFAIL标记另一个节点。主节点和从节点都可以将另一个节点标记为PFAIL，而不管其类型如何。

KeyDB集群节点的不可到达性的概念是，我们有一个 **active ping**（我们发送的ping尚未得到回复）等待的时间超过了NODE_TIMEOUT。
要使此机制工作，NODE_TIMEOUT必须比网络往返时间大。为了在正常操作期间增加可靠性，节点将尝试在NODE_TIMEOUT的一半时间过后重新连接到群集中的其他节点，
而不回复ping。
此机制确保连接保持活动状态，因此断开的连接通常不会导致节点之间的错误故障报告。

#### FAIL flag:

PFAIL标志本身只是每个节点关于其他节点的本地信息，但不足以触发从属提升。
对于要被视为向下的节点，需要将PFAIL条件升级为FAIL条件。

如本文档节点心跳部分所述，每个节点都向每个其他节点发送gossip消息，包括一些随机已知节点的状态。
每个节点最终都会为其他每个节点接收一组节点标志。
这样，每个节点都有一个机制，向其他节点发送它们检测到的故障情况的信号。

当满足以下一组条件时，PFAIL条件将升级为FAIL条件：

* 某个节点（我们称之为A）的另一个节点B被标记为PFAIL。
* 节点A通过gossip部分从集群中大多数主节点的角度来看关于B的状态的信息。
* 大多数主机在节点超时*故障报告有效期多时间内发出PFAIL或FAIL条件的信号。（在当前实现中，有效性因子设置为2，因此这只是节点超时时间的两倍）。

如果上述所有条件均为真，则节点A将：

* 将节点标记为失败。
* 向所有可访问的节点发送失败消息。

FAIL消息将强制每个接收节点将该节点标记为FAIL状态，无论它是否已将该节点标记为PFAIL状态。
注意，FAIL标志主要是单向的。也就是说，节点可以从PFAIL变为FAIL，但FAIL标志只能在以下情况下清除：

* 节点已经可以访问，并且是从节点。在这种情况下，可以清除FAIL标志，因为从设备没有故障转移。
* 节点已经可以访问，并且是一个不为任何插槽提供服务的主节点。在这种情况下，可以清除FAIL标志，
因为没有插槽的主节点不真正参与集群，并且正在等待配置以加入集群。
* 节点已经可以访问并且是主节点，但是经过很长时间（NODE_TIMEOUT的N倍）而没有任何可检测的从节点提升。它最好重新加入集群并在这种情况下继续。

需要注意的是，虽然PFAIL->FAIL转换使用协议的形式，但使用的协议很弱：

1.节点在一段时间内收集其他节点的视图，所以即使大多数主节点需要"agree"，实际上这只是我们在不同时间从不同节点收集的状态，
我们不确定，也不要求，在给定的时刻大多数主节点同意。然而，我们丢弃的失败报告是旧的，所以失败是由大多数主人在一段时间内发出的信号。

2.虽然每个检测到FAIL条件的节点都将使用FAIL消息在集群中的其他节点上强制执行该条件，但无法确保消息将到达所有节点。
例如，一个节点可能会检测到故障情况，并且由于分区的原因，无法到达任何其他节点。

然而，KeyDB集群故障检测有一个活跃性要求：最终所有节点都应该同意给定节点的状态。
有两种情况可能源于脑裂。要么少数节点认为节点处于FAIL失败状态，要么少数节点认为节点未处于FAIL失败状态。
在这两种情况下，集群最终都将拥有给定节点状态的单一视图：

**案例1：** 如果大多数主节点都将一个节点标记为FAIL，那么由于故障检测和它所产生的链效应，
每个其他节点最终都将主节点标记为FAIL，因为在指定的时间窗口中，将报告足够多的故障。

**案例2：** 当只有少数主节点标记为FAIL时，从机升级不会发生（因为它使用了一个更正式的算法，确保每个人最终都知道升级），
每个节点都将按照上面的FAIL状态清除规则清除FAIL状态（即NODE_TIMEOUT N次后不升级）。

**FAIL标志仅用作触发器，用于运行从机提升算法的安全部分。** 从理论上讲，当一个从机不能到达它的主机时，它可以独立行动并启动一个从机提升，并且等待主机拒绝提供确认，如果主机实际上是大多数人可以到达的。
然而，PFAIL -> FAIL 状态的复杂性，弱协议，以及在集群的可达部分中最短时间内强制状态传播的失败消息具有实际优势。
由于这些机制，如果集群处于FAIL状态，通常所有节点都会在大约相同的时间停止接受写操作。
从使用KeyDB集群的应用程序的角度来看，这是一个理想的特性。此外，还避免了由于本地问题而无法到达主节点的从节点发起的错误选择尝试（主节点在其他情况下可由大多数其他主节点到达）。

# 配置处理、传播和故障转移

## 群集当前epoch纪元

KeyDB集群使用了类似Raft算法"term"的概念。在KeyDB集群中，这个术语被称为epoch，
它用于为事件提供增量版本控制。当多个节点提供冲突信息时，另一个节点可能了解哪个状态是最新的。

currentEpoch 是一个 64位无符号数字

在创建节点时，每个KeyDB集群节点（从节点和主节点）都将currenteepoch设置为0。

每次从另一个节点接收数据包时，如果发送方的epoch（集群总线消息头的一部分）大于本地节点epoch，
则currentpoch将更新为发送方epoch。

由于这些语义，最终所有节点都将同意集群中最大的configEpoch。

当集群的状态发生更改并且节点为了执行某些操作而寻求协议时，将使用此信息。

目前，这种情况只在slave提升期间发生，如下一节所述。基本上，epoch是集群的一个逻辑时钟，它指示给定的信息比epoch小的信息赢得更多。

## 配置epoch纪元

每一个主机总是在ping和pong包中公布它的配置时间，同时用位图公布它所服务的插槽集。

创建新节点时，主节点中的configEpoch设置为零。

在slave选举期间创建新的configEpoch。slave试图取代失败的master增加他们的时代，并试图获得大多数Master的授权。
当一个从机被授权时，将创建一个新的唯一configEpoch，并使用新的configEpoch将该slave变成master。

正如在下一节中所解释的，configEpoch有助于解决不同节点声明不同配置时的冲突（这种情况可能是由于网络分区和节点故障造成的）。

从节点也在ping和pong数据包中公布configEpoch字段，但对于slave从节点，该字段表示其master节点上次交换数据包时的configEpoch。
这允许其他实例检测slave从机何时具有需要更新的旧配置（master节点不会将投票权授予具有旧配置的slave机）。

每当某个已知节点的configEpoch发生更改时，接收此信息的所有节点都会将其永久存储在nodes.conf文件中。
currentEpoch值也会发生同样的情况。在节点继续其操作之前，这两个变量保证在更新时保存并同步到磁盘。

故障转移期间使用简单算法生成的configEpoch值保证是新的、增量的和唯一的。

## slave选举和提升

slave选举和提升由slave节点处理，由投票给slave提升的master节点帮助。从slave中至少有一个slave的角度来看，当master处于FAIL状态时，
slave选举就发生了，这些slave具备成为master的先决条件。

为了让slave提升自己成为master，它需要开始选举并赢得选举。如果master处于FAIL状态，所有slave都可以开始选举，
但是只有一个slave会赢得选举并提升自己成为master。


当满足下列条件时，slave开始选举：

* slave的master处于失败状态。
* master服务器正在为非零个插槽提供服务。
* slave复制链接从master服务器断开的时间不超过给定的时间，以确保提升的slave服务器的数据是合理的新鲜的。这一次是用户可配置的。

为了被选中，slave的第一步是增加其currentEpoch计数器，并从master实例请求投票。

slave是通过广播FAILOVER_AUTH_REQUEST包给集中的每一个masters。slave节点发起投票后,
会等待至少两倍NODE_TIMEOUT时长接收投票结果，不管NODE_TIMEOUT何值，也至少会等待2秒。

一旦一个master服务器为一个给定的slave服务器投票，并使用FAILOVER_AUTH_ACK进行积极响应，
那么在NODE_TIMEOUT * 2的时间段内，它就不能再为同一个master服务器的另一个slave服务器投票了。
在此期间，它将无法回复同一主机的其他授权请求。这不是为了保证安全，而是为了防止多个slave同时当选(即使是不同的选举)，这通常是不需要的。

slave丢弃任何AUTH_ACK应答，并且应答的epoch纪元小于发送投票请求时的currentEpoch。这就保证了它不会计算前一次选举的选票。

一旦slave从多数master那里得到开票，它就赢得了选举。否则，如果在两次NODE_TIMEOUT(但总是至少2秒)期间内没有达到多数，
则选举将被中止，并且在NODE_TIMEOUT * 4之后将再次尝试一个新的选举(并且总是至少4秒)。

## slave等级

一旦主人处于FAIL状态，slave在试图当选之前会等待一段时间。延迟的计算方法如下:

    DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +
            SLAVE_RANK * 1000 milliseconds.

固定的延迟确保我们等待失败状态在集群中传播，否则奴隶可能试图在主人仍然不知道失败状态的情况下当选，拒绝授予他们的投票。

随机延迟被用来取消slave的同步，所以他们不太可能同时开始选举。

SLAVE_RANK是这个从服务器处理的复制数据量的秩。当主进程失败时，从进程交换消息以建立一个(最佳努力)级别: 
复制偏移量更新最快的从进程在第0级，第2个更新最快的在第1级，以此类推。
通过这种方式，最新的奴隶试图在其他人之前被选上。

等级次序不严格;如果一个等级高的slave没有被选上，其他的slave很快就会尝试。

一旦一个slave赢得了选举，它就会获得一个新的唯一的和递增的比任何其他现有的master更高的配置。
它开始宣传自己是ping和乒pong的master选手，用一种比过去更有胜算的招数来提供一套发球点。

为了加速其他节点的重新配置，一个pong包被广播到集群的所有节点。当前不可到达的节点最终将在从另一个节点接收到ping或pong包时重新配置，
或者在检测到通过heartbeat包发布的信息过期时从另一个节点接收UPDATE包。

其他节点将检测到有一个新master节点提供与旧master节点相同的插槽，但具有更大的configEpoch，并将升级它们的配置。
旧master的slave服务器(或重新加入集群的失败的转移master服务器)不仅会升级配置，
还会重新配置以从新master服务器复制。下一节将解释如何配置重新加入集群的节点。

## master回复slave投票请求

在前面的章节中，我们讨论了slave是如何被选举的。本节将从请求为给定的slave投票的主人的角度解释所发生的事情。

slave服务器接收来自slave服务器的FAILOVER_AUTH_REQUEST请求。

为使投票获得通过，必须满足下列条件:
1.一个master只对给定的epoch纪元进行一次投票，并且拒绝对更早的epoch纪元进行投票: 每个master都有一个lastVoteEpoch字段，
  并且只要验证请求包中的currentEpoch不大于lastVoteEpoch，他就会拒绝再次投票。
  当master服务器对投票请求做出肯定的响应时，lastVoteEpoch将相应地更新，并安全地存储在磁盘上。
2.只有在slave的master被标记为失败时，master才会投票给slave。
3.带有小于主currentEpoch的currentEpoch的Auth请求将被忽略。
  因此，master应答将始终具有与验证请求相同的currentEpoch。如果相同的slave再次要求被投票，增加currentEpoch，这是保证一个旧的延迟答复从主人不能接受的新投票。

不使用规则3导致的问题示例:

Master currentEpoch是5,lastVoteEpoch是1(这可能发生在几次失败的选举之后)

* Slave currentEpoch 是 3.
* Slave 试图与epoch历元4(3+1)被选举，主人与currentEpoch 5用一个确定答复，然而答复被延迟
* Slave 将尝试再次当选，在以后的时间，在epoch纪元5(4+1)，延迟的答复到达slave与currentEpoch 5，并被视为有效。
* 在NODE_TIMEOUT * 2结束之前，如果已经投票给同一主机的一个slave，那么该主机的slave将不会被投票给它。
  这并不是严格要求的，因为两个slave不可能在同一时代赢得选举。然而，在实践中，它可以确保当一个奴隶被选上时，它有足够的时间通知其他slave，
  并避免另一个slave赢得新选举的可能性，从而执行不必要的第二次故障转移。
* Masters无论如何也不去挑选最好的slave。如果slave的master处于失败状态，并且master在当前的任期内没有投票，则授予一个积极的投票。
  最好的slave是最有可能开始选举并在其他slave之前赢得选举的，因为它通常能够更早地开始投票过程，因为它的等级更高，如前一节所述。
* 当一个master拒绝为一个给定的slave投票时，没有否定的回答，请求被简单地忽略。   
* master不会投票给slave发送的configEpoch比主表中任何configEpoch都要少，因为slave需要这些槽。记得slave送它的master的configEpoch，
和它的master服务的槽的位图。这意味着请求投票的slave服务器必须对它希望进行故障转移的插槽进行更新或与授予投票的master服务器相同的配置。

## 分区期间配置epoch有用性的实例

本节说明如何使用epoch概念使slave提升过程对分区更具抵抗力。

* master服务器不再是可以无限访问的。master有三个slave A, B, C。
* slave A赢得了选举，被提升为master。
* 网络分区使A对大多数集群不可用。
* slave B赢得了选举，被提升为master。
* 一个分区使得B对于大多数集群不可用。
* 前一个分区是固定的，A再次可用。

此时，B停止工作，A再次可用，角色为master(实际上UPDATE消息会立即重新配置它，但这里我们假设所有更新消息都丢失了)。与此同时，slave C会试图通过选举来击败B。

1. C将努力获得选举并取得成功，因为对于大多数的master来说，它的master实际上是堕落的。它将获得一个新的增量configEpoch。

2. A将不能声称是其哈希槽的主节点，因为与A发布的哈希槽相比，其他节点已经具有与更高配置epoch历元(B的epoch历元)相关联的相同哈希槽。

3. 因此，所有节点将升级它们的表，将哈希槽分配给C，集群将继续其操作。

正如您将在下一节中看到的，旧的节点重新加入集群通常会尽快得到关于配置更改的通知，因为一旦它ping任何其他节点，接收方就会检测到它有旧的信息，并发送UPDATE消息。

## 哈希槽配置传播

KeyDB集群的一个重要部分是用于传播关于哪个集群节点为给定的一组散列槽提供服务的信息的机制。这对于新集群的启动和升级配置的能力都是至关重要的。

相同的机制允许在不确定的时间内分区的节点以合理的方式重新加入集群。

有两种方式哈希槽配置传播:

1.Heartbeat 信息。ping或pong包的发送者总是添加关于它(或它的master，如果它是slave的话)所服务的哈希槽集的信息。
2.UPDATE 消息。因为在每个heartbeat包中都有关于发送方的configEpoch和一组哈希槽的信息，如果心跳包的接收方发现发送方的信息过时了，它就会发送一个包含新信息的包，迫使过时的节点更新信息。

heartbeat或UPDATE消息的接收方使用某些简单的规则来更新其将哈希槽映射到节点的表。当创建一个新的KeyDB集群节点时，它的本地哈希槽表被初始化为空条目，这样每个哈希槽就不会被绑定或链接到任何节点。这看起来像下面这样:

	0 -> NULL
	1 -> NULL
	2 -> NULL
	...
	16383 -> NULL

节点更新哈希槽表的第一个规则如下:

**规则1:** 如果一个散列槽未被分配(设置为NULL)，并且一个已知节点声明它，那么我将修改我的散列槽表，并将声明的散列槽与它关联。

因此，如果我们从节点a接收到一个声称提供哈希槽1和2的心跳，配置epoch历元值为3，表将被修改为:

	0 -> NULL
	1 -> A [3]
	2 -> A [3]
	...
	16383 -> NULL

在创建新集群时，系统管理员需要手动分配(使用cluster addslot命令，通过keydb-trib命令行工具或其他任何方法)每个主节点提供的插槽仅分配给节点本身，信息将在集群中迅速传播。

然而，这个规则是不够的。我们知道哈希槽映射可以在两个事件中改变:

1.在故障转移期间，slave服务器替换其master服务器。
2.槽从节点重新分片到另一个节点。

现在让我们关注故障转移。当一个从服务器对它的主服务器发生故障时，它将获得一个配置epoch历元，这个配置epoch历元保证大于它的master服务器的配置epoch历元(并且通常大于以前生成的任何其他配置epoch历元)。例如节点B，它是A的一个slave，可能故障转移B的配置epoch历元为4。它将开始发送心跳包(第一次在集群范围内进行大规模广播)，由于第二条规则，接收者将更新他们的哈希槽表:

**规则2:** 如果已经分配了一个哈希槽，并且已知节点使用的configEpoch大于当前与该槽关联的主节点的configEpoch，那么我将把这个哈希槽重新绑定到新节点。

因此，在接收到B声称提供配置epoch历元为4的哈希槽1和2的消息后，接收者将以以下方式更新其表:

	0 -> NULL
	1 -> B [4]
	2 -> B [4]
	...
	16383 -> NULL

活性属性: 由于第二条规则，集群中的所有节点最终都会一致认为槽的所有者是 所有节点中对插槽进行configEpoch的那个人。

KeyDB集群中的这种机制称为**最后故障转移wins**。

在重新分片期间也会发生相同的情况。当导入散列槽的节点完成导入操作时，将增加其配置epoch历元，以确保更改将在整个集群中传播。

## 更新消息，仔细看看

考虑到前面的部分，更容易看到更新消息是如何工作的。节点A可能在一段时间后重新加入群集。
它将发送heartbeat数据包，声称它为哈希槽1和2提供配置epoch为3的服务。所有具有更新信息的接收器将看到相同的哈希槽与具有更高配置epoch的节点B相关联。
因此，他们将用插槽的新配置向发送更新消息。由于上面的规则2，A将更新其配置。

## 节点如何重新加入群集

当节点重新加入集群时，使用相同的基本机制。继续上面的示例，节点A将被通知散列槽1和2现在由B提供服务。
假设这两个是A提供服务的唯一散列槽，则A提供服务的散列槽的计数将降至0！因此**A将重新配置为新主服务器的从服务器。**

实际遵循的规则要比这个复杂一些。一般来说，A在经过很长时间后可能会发生重新连接，同时可能会发生最初由A服务的散列槽被多个节点服务，例如散列槽1可以由B服务，散列槽2可以由C服务。

因此，实际的KeyDB集群节点角色切换规则是：**主节点将更改其配置以复制（从）窃取其最后一个哈希槽的节点。**

在重新配置期间，最终服务的哈希槽的数量将降至零，节点将相应地重新配置。
注意，在基本情况下，这只是意味着旧主服务器将是在故障转移后替换它的从服务器的从服务器。
不过，一般来说，这条规则涵盖了所有可能的情况。

从节点做的完全相同：它们重新配置以复制窃取其前主节点的最后一个散列槽的节点。

## 复制副本迁移

KeyDB集群实现了一个称为副本迁移的概念，以提高系统的可用性。其思想是，在具有主从设置的集群中，如果从节点和主节点之间的映射是固定的，
那么当单个节点发生多个独立故障时，随着时间的推移，可用性是有限的。

例如，在每个主节点都有一个从节点的集群中，只要主节点或从节点都出现故障，集群就可以继续操作，但如果两个节点同时出现故障，集群就不能继续操作。
然而，有一类故障是由硬件或软件问题引起的单个节点的独立故障，这些故障会随着时间的推移而累积。例如：

* Master A有一个slave A1。
* Master A失败了。A1被提升为新Master。
* 三小时后A1以独立方式失效（与A的失效无关）。由于节点A仍处于关闭状态，因此没有其他从机可供升级。群集无法继续正常操作。

如果主服务器和从服务器之间的映射是固定的，那么使集群更能抵抗上述场景的唯一方法是向每个主服务器添加从服务器，
但是这是昂贵的，因为它需要执行更多的KeyDB实例、更多的内存等等。

另一种方法是在集群中创建一个非对称性，并让集群布局随时间自动更改。例如，集群可以有三个主机A、B、C。
A和B各有一个从机A1和B1。但是主C是不同的，它有两个从机：C1和C2。

复制副本迁移是为了迁移到不再覆盖的主机（没有工作的从机）而自动重新配置从机的过程。
通过复制副本迁移，上面提到的场景将变成以下场景：

* Master A失败了。A1被提升。
* C2作为A1的slave迁移，否则就没有任何slave支持。
* 三小时后A1也失败了。
* C2升级为新的Mater控来代替A1。
* 群集可以继续操作

## Replica副本迁移算法

迁移算法不使用任何形式的协议，因为KeyDB集群中的从属布局不是需要与配置阶段保持一致和/或版本控制的集群配置的一部分。
相反，它使用一种算法来避免当主服务器没有备份时从服务器的大规模迁移。该算法保证最终（一旦集群配置稳定）每个主服务器将至少有一个从服务器作为备份。

这就是算法的工作原理。首先，我们需要定义在这个上下文中什么是好的从机：从给定节点的角度来看，好的从机是不处于失败状态的从机。

算法的执行在每个从机中触发，检测到至少有一个主机没有好的从机。然而，在所有检测到这种情况的从机中，只有一个子集应该起作用。
这个子集实际上通常是一个从节点，除非不同的从节点在给定时刻对其他节点的故障状态有稍微不同的看法。

扮演奴隶的主人是奴隶中奴隶数量最多的奴隶，不是处于失败状态，而是最小的node ID.。

因此，例如，如果有10个主节点，每个主节点有1个从节点，而2个主节点有5个从节点，那么尝试迁移的从节点是具有5个从节点的2个主节点中节点ID最低的一个。
如果没有使用协议，那么当集群配置不稳定时，当多个从机认为自己是具有较低节点ID的非故障从机时，就会发生竞争条件（在实践中不太可能发生这种情况）。
如果发生这种情况，结果是多个从机迁移到同一主机，这是无害的。如果竞争发生的方式将使割让主服务器没有从服务器，一旦集群再次稳定，算法将再次执行，并将从服务器迁移回原始主服务器。

最终，每一个主人都会得到至少一个奴隶的支持。然而，正常的行为是一个从机从一个有多个从机的主机迁移到一个孤立的主机。

该算法由一个名为cluster migration barrier的用户可配置参数控制：在一个从机可以迁移出去之前，主机必须保留好的从机数量。例如，如果此参数设置为2，则从属服务器只能在其主服务器保留两个工作从属服务器的情况下尝试迁移.

## configEpoch冲突解决算法

当在故障转移期间通过从机提升创建新的configEpoch值时，它们保证是唯一的。

但是，有两个不同的事件以不安全的方式创建新的configEpoch值，它们只是增加本地节点的本地currentEoch，并希望同时不发生冲突。这两个事件都由系统管理员触发：

1.带TAKEOVER选项的CLUSTER FAILOVER命令能够在没有大多数主节点可用的情况下手动将从节点提升到主节点。
  例如，在多数据中心设置中，这很有用。
2.迁移用于群集重新平衡的时隙也会在本地节点内生成新的配置时段，而不必出于性能原因达成一致。

具体来说，在手动重设期间，当散列槽从节点a迁移到节点B时，重设程序将强制B将其配置升级到集群中发现的最大epoch，加上1（除非该节点已经是配置epoch最大的节点），而不需要其他节点的同意。
通常，真实世界中的重装需要移动几百个散列槽（特别是在小集群中）。对于移动的每个散列槽，在重新硬装期间要求协议生成新的配置时段是低效的。
此外，每次在每个集群节点中都需要一个fsync来存储新的配置。由于它的执行方式，我们只需要在第一个散列槽被移动时使用一个新的配置epoch，这使得它在生产环境中更加高效。

然而，由于以上两种情况，有可能（尽管不太可能）以具有相同配置纪元的多个节点结束。
如果系统管理员执行的重新硬盘操作和同时发生的故障转移（加上许多坏运气）传播得不够快，则可能会导致currentEpoch冲突。

此外，软件bugs和文件系统损坏也会导致多个节点具有相同的配置周期。

当服务于不同散列槽的主服务器具有相同的configEpoch时，不存在问题。更重要的是，故障转移到主服务器的从属服务器具有唯一的配置时段。

也就是说，手动干预或重新硬化可能以不同的方式改变集群配置。KeyDB Cluster main liveness属性要求时隙配置总是收敛的，因此在任何情况下我们都希望所有主节点都有不同的configEpoch。

为了实现这一点，在两个节点以相同的configEpoch结束时使用**冲突解决算法**。

* 如果主节点检测到另一个主节点正在使用相同的configEpoch播发自身。
* 并且如果节点与另一个声称相同配置周期的节点相比，则具有比字典更小的节点ID。
* 然后它将currentEpoch增加1，并将其用作新的configEpoch。

如果有任何一组节点具有相同的configEpoch，那么除了具有最大节点ID的节点之外，所有节点都将向前移动，从而保证最终每个节点都将选择一个唯一的configEpoch，而不管发生了什么。

此机制还保证在创建新集群之后，所有节点都以不同的CONFIG EPOCH开始（即使实际上没有使用），因为keydb-trib确保在启动时使用CONFIG SET-CONFIG-EPOCH。
但是，如果由于某种原因某个节点配置错误，它将自动将其配置更新到不同的配置epoch。

## 节点重置

节点可以被软件重置（不需要重新启动它们），以便在不同的角色或集群中重用。
这在正常操作、测试和云环境中都很有用，在这些环境中，可以重新配置给定的节点以加入不同的节点集以扩大或创建新的集群。

在KeyDB中，使用CLUSTER RESET命令重置集群节点。命令有两种变体：

* CLUSTER RESET SOFT
* CLUSTER RESET HARD

命令必须直接发送到节点才能重置。如果未提供重置类型，则执行软重置。

以下是重置执行的操作列表：

1.软硬件重置：如果节点是从节点，则将其转换为主节点，并丢弃其数据集。如果节点是主节点并且包含密钥，则会中止重置操作。
2.软、硬复位：所有插槽释放，手动故障切换状态复位。
3.软重置和硬重置：节点表中的所有其他节点都被移除，因此节点不再知道任何其他节点。
4.仅硬重置：currentEpoch、configEpoch和lastVoteEpoch设置为0。
5.仅限硬重置：节点ID更改为新的随机ID。

无法重置具有非空数据集的主节点（因为通常要将数据重新硬装到其他节点）。但是，在适当的特殊条件下（例如，当一个集群为了创建一个新集群而被完全销毁时），
必须在继续重置之前执行FLUSHALL。

## 从群集中删除节点

通过将所有的数据重新绑定到其他节点（如果它是主节点）并关闭它，实际上可以从现有的集群中删除节点。
但是，其他节点仍会记住其节点ID和地址，并尝试与之连接。

因此，当一个节点被删除时，我们还想从所有其他节点表中删除它的条目。
这是通过使用CLUSTER FORGET <node id> 命令实现的。

这个命令有两个作用：

1.它从nodes表中删除具有指定节点ID的节点。
2.它设置了一个60秒的禁止，防止具有相同节点ID的节点被重新添加。

第二个操作是必需的，因为KeyDB Cluster使用gossip来自动发现节点，因此从节点A中删除节点X可能会导致节点B再次对节点X进行gossip。
由于60秒的禁止，KeyDB集群管理工具有60秒的时间从所有节点中删除节点，防止由于自动发现而重新添加节点。

CLUSTER FORGET文档中提供了更多信息。

# 发布/订阅

在KeyDB集群中，客户机可以订阅每个节点，也可以发布到其他每个节点。群集将确保根据需要转发已发布的消息。

当前的实现将简单地将每个发布的消息广播到所有其他节点，但在某些时候，这将使用Bloom过滤器或其他算法进行优化。
